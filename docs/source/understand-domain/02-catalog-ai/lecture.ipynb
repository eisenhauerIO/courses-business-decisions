{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de5367a-6764-499f-a10e-923c517ab00e",
   "metadata": {},
   "source": [
    "# **Catalog AI**\n",
    "\n",
    "This notebook implements a toy version of the **Catalog AI** system discussed in [Addressing Gen AI's Quality Control Problem](https://hbr.org/2025/09/addressing-gen-ais-quality-control-problem) (Harvard Business Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca56e9e9-7e5c-4928-b760-f9c696c592e3",
   "metadata": {},
   "source": [
    "![description](../01-online-retail-simulator/article.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c120dd0-64f6-4163-b74f-8573592b1420",
   "metadata": {},
   "source": [
    "Generative AI systems can produce vast numbers of candidate product data improvements, but at scale the central problem is not generation—it is quality control and learning. When Amazon began automating product data improvements using large language models to enhance product `title`, `description`, and `features`, most generated outputs were initially unreliable, and only a small fraction improved business outcomes like conversion and revenue. The solution was not human review, but a self-learning system that combines automated guardrails to filter low-quality outputs, experimentation to measure impact on shopper behavior, and feedback loops that use experimental results to guide future generation. The system can test millions of product data hypotheses, discard most of them, and continuously learn from the few that work. \n",
    "\n",
    "This notebook introduces a simplified, toy version of that idea: how to build a <img src=\"../../_static/learn-decide-repeat.png\" alt=\"LDR\" style=\"height: 1em; vertical-align: middle;\"> **Learn · Decide · Repeat** loop that turns large-scale product data analysis into action and learning over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638e845-0d5a-4886-a006-6ad8ccc03e29",
   "metadata": {},
   "source": [
    "![description](../01-online-retail-simulator/online-retail-simulator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1aee6f-ae6e-4bae-8f86-34666174b15e",
   "metadata": {},
   "source": [
    "We use the **[Online Retail Simulator](https://github.com/eisenhauerIO/tools-catalog-generator)** to demonstrate three capabilities. First, we generate product `title`, `description`, and `features` using a local LLM via [**Ollama**](https://ollama.com/) with customizable prompts. Using simulated data, we then apply causal impact measurement to establish whether these content improvements actually drive shopper behavior and sales, and to identify which positioning strategy—luxury versus budget—produces the strongest business outcomes. This illustrates how impact measurement guides data-driven content strategy selection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "Before running this notebook, execute the setup script `\"setup_catalog_ai.sh\"` to install and configure Ollama:\n",
    "\n",
    "```bash\n",
    "bash setup_catalog_ai.sh\n",
    "```\n",
    "\n",
    "The script installs the Online Retail Simulator package and sets up Ollama with the `llama3.2` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "from online_retail_simulator import simulate, load_job_results\n",
    "from support import print_product_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "The **Ollama backend** uses a local LLM to generate unique, contextually-aware product `title`, `description`, and `features`. Custom prompts let you control the tone and style—enabling different positioning for the same products. Let's compare **luxury** vs **budget** positioning for the same products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate base product catalog with characteristics\n",
    "job_info = simulate(\"config_simulation.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s6fnvncj7mc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the generated product data\n",
    "products = load_job_results(job_info)[\"products\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jwlzc66rvsd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 2 products for demonstration\n",
    "sample_products = products[[\"product_identifier\", \"category\", \"price\"]].head(2)\n",
    "sample_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the luxury positioning prompt template\n",
    "!cat prompt_luxury.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166de197-f6a1-4817-922c-7a776ed2f505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the budget positioning prompt template\n",
    "!cat prompt_budget.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b19d57-4a69-489d-aaf7-e50cf55b7251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import inspect\n",
    "\n",
    "# Third-party packages\n",
    "from IPython.display import Code\n",
    "\n",
    "# Local imports\n",
    "from online_retail_simulator.simulate.product_details_ollama import simulate_product_details_ollama\n",
    "\n",
    "Code(inspect.getsource(simulate_product_details_ollama), language=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate luxury-positioned product content using Ollama LLM\n",
    "luxury_products = simulate_product_details_ollama(sample_products, prompt_path=\"prompt_luxury.txt\")\n",
    "print_product_details(luxury_products, \"Luxury\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb45e138-20bd-4e22-9cdf-3db1df30a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate budget-positioned product content using Ollama LLM\n",
    "budget_products = simulate_product_details_ollama(sample_products, prompt_path=\"prompt_budget.txt\")\n",
    "print_product_details(budget_products, \"Budget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "The same product generates completely different content depending on the prompt—enabling A/B testing of content strategies, audience targeting, and channel customization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  },
  "nbsphinx": {
   "execute": "never"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
