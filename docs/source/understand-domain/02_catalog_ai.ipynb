{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3de5367a-6764-499f-a10e-923c517ab00e",
   "metadata": {},
   "source": [
    "# Catalog AI: AI-Powered Product Data Improvements\n",
    "\n",
    "This notebook implements a toy version of the **Catalog AI** system discussed in [Addressing Gen AI's Quality Control Problem](https://hbr.org/2025/09/addressing-gen-ais-quality-control-problem) (Harvard Business Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca56e9e9-7e5c-4928-b760-f9c696c592e3",
   "metadata": {},
   "source": [
    "![description](_static/article.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c120dd0-64f6-4163-b74f-8573592b1420",
   "metadata": {},
   "source": [
    "Generative AI systems can produce vast numbers of candidate actions, but at scale the central problem is not generation—it is quality control and learning. When Amazon began automating the creation of product pages using large language models, most generated outputs were initially unreliable, and only a small fraction improved business outcomes. The solution was not better prompts or more human review, but a system: automated guardrails to filter low-quality outputs, experimentation to measure impact, and feedback loops that used experimental results to improve future generation. By combining causal measurement, decision rules, and software infrastructure, the system could test millions of hypotheses, discard most of them, and continuously learn from the few that worked. This notebook introduces a simplified, toy version of that idea: how to build a Learn · Decide · Repeat loop that turns large-scale analysis into action and learning over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638e845-0d5a-4886-a006-6ad8ccc03e29",
   "metadata": {},
   "source": [
    "![description](_static/online-retail-simulator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1aee6f-ae6e-4bae-8f86-34666174b15e",
   "metadata": {},
   "source": [
    "We use th using the [Online Retail Simulator](https://github.com/eisenhauerIO/tools-catalog-generator). We demonstrate two key capabilities: 1. **LLM-generated product details** - Using local models via Ollama to create unique titles, descriptions, and features\n",
    "2. **Causal impact measurement** - Simulating and visualizing the effect of improved product content on sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aacb7a45-901c-4238-8490-cef8d0db1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq git+https://github.com/eisenhauerIO/tools-catalog-generator.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "Before running this notebook, execute the setup script to install and configure Ollama:\n",
    "\n",
    "```bash\n",
    "bash setup_catalog_ai.sh\n",
    "```\n",
    "\n",
    "The script installs the Online Retail Simulator package and sets up Ollama with the `llama3.2` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from online_retail_simulator import simulate, load_job_results\n",
    "from support import print_product_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "The **Ollama backend** uses a local LLM to generate unique, contextually-aware product titles, descriptions, and features. Custom prompts let you control the tone and style—enabling different positioning for the same products. Let's compare **luxury** vs **budget** positioning for the same products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>category</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRPOIG8F1C</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>19.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BO6B9M80O2</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>185.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin     category   price\n",
       "0  BRPOIG8F1C     Clothing   19.63\n",
       "1  BO6B9M80O2  Electronics  185.86"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate base products\n",
    "job_info = simulate(\"config_simulation.yaml\")\n",
    "products = load_job_results(job_info)[\"products\"]\n",
    "\n",
    "# Select 2 for demonstration\n",
    "sample_products = products[[\"asin\", \"category\", \"price\"]].head(2)\n",
    "sample_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a JSON generator for luxury e-commerce products.\n",
      "Generate premium, aspirational product details.\n",
      "\n",
      "Products:\n",
      "{products_json}\n",
      "\n",
      "For each product, add:\n",
      "- title: Elegant product title (50-100 chars) with premium feel\n",
      "- description: Luxurious description (100-300 chars) emphasizing quality and exclusivity\n",
      "- brand: Premium-sounding brand name\n",
      "- features: List of 3-5 premium features\n",
      "\n",
      "Response must be ONLY valid JSON starting with [ and ending with ].\n"
     ]
    }
   ],
   "source": [
    "!cat prompt_luxury.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "166de197-f6a1-4817-922c-7a776ed2f505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a JSON generator for budget-friendly e-commerce products.\n",
      "Generate practical, value-focused product details.\n",
      "\n",
      "Products:\n",
      "{products_json}\n",
      "\n",
      "For each product, add:\n",
      "- title: Clear product title (50-100 chars) emphasizing value\n",
      "- description: Practical description (100-300 chars) focusing on functionality and savings\n",
      "- brand: Approachable brand name\n",
      "- features: List of 3-5 practical features\n",
      "\n",
      "Response must be ONLY valid JSON starting with [ and ending with ].\n"
     ]
    }
   ],
   "source": [
    "!cat prompt_budget.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b19d57-4a69-489d-aaf7-e50cf55b7251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #F00 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #04D } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #00F; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #800 } /* Name.Constant */\n",
       ".output_html .nd { color: #A2F } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #00F } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #00F; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #A2F; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #BBB } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #00F } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"k\">def</span><span class=\"w\"> </span><span class=\"nf\">simulate_product_details_ollama</span><span class=\"p\">(</span>\n",
       "    <span class=\"n\">products_df</span><span class=\"p\">:</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"n\">DEFAULT_MODEL</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">ollama_url</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"n\">OLLAMA_URL</span><span class=\"p\">,</span>\n",
       "    <span class=\"n\">prompt_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span> <span class=\"o\">=</span> <span class=\"kc\">None</span><span class=\"p\">,</span>\n",
       "<span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">:</span>\n",
       "<span class=\"w\">    </span><span class=\"sd\">&quot;&quot;&quot;Generate product details using Ollama (local LLM).</span>\n",
       "\n",
       "<span class=\"sd\">    Args:</span>\n",
       "<span class=\"sd\">        products_df: Input products with asin, category, price</span>\n",
       "<span class=\"sd\">        model: Ollama model to use (default: llama3.2)</span>\n",
       "<span class=\"sd\">        ollama_url: Ollama API URL (default: http://localhost:11434)</span>\n",
       "<span class=\"sd\">        prompt_path: Optional path to custom prompt template file.</span>\n",
       "<span class=\"sd\">            Template should contain {products_json} placeholder.</span>\n",
       "\n",
       "<span class=\"sd\">    Returns:</span>\n",
       "<span class=\"sd\">        DataFrame with added title, description, brand, features</span>\n",
       "<span class=\"sd\">    &quot;&quot;&quot;</span>\n",
       "    <span class=\"c1\"># Load custom prompt or use default</span>\n",
       "    <span class=\"n\">prompt_template</span> <span class=\"o\">=</span> <span class=\"n\">_load_prompt_template</span><span class=\"p\">(</span><span class=\"n\">prompt_path</span><span class=\"p\">)</span> <span class=\"k\">if</span> <span class=\"n\">prompt_path</span> <span class=\"k\">else</span> <span class=\"n\">PROMPT_TEMPLATE</span>\n",
       "\n",
       "    <span class=\"n\">results</span> <span class=\"o\">=</span> <span class=\"p\">[]</span>\n",
       "    <span class=\"n\">products</span> <span class=\"o\">=</span> <span class=\"n\">products_df</span><span class=\"o\">.</span><span class=\"n\">to_dict</span><span class=\"p\">(</span><span class=\"s2\">&quot;records&quot;</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">for</span> <span class=\"n\">i</span> <span class=\"ow\">in</span> <span class=\"nb\">range</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">products</span><span class=\"p\">),</span> <span class=\"n\">DEFAULT_BATCH_SIZE</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">batch</span> <span class=\"o\">=</span> <span class=\"n\">products</span><span class=\"p\">[</span><span class=\"n\">i</span> <span class=\"p\">:</span> <span class=\"n\">i</span> <span class=\"o\">+</span> <span class=\"n\">DEFAULT_BATCH_SIZE</span><span class=\"p\">]</span>\n",
       "        <span class=\"n\">prompt</span> <span class=\"o\">=</span> <span class=\"n\">prompt_template</span><span class=\"o\">.</span><span class=\"n\">format</span><span class=\"p\">(</span><span class=\"n\">products_json</span><span class=\"o\">=</span><span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">dumps</span><span class=\"p\">(</span><span class=\"n\">batch</span><span class=\"p\">,</span> <span class=\"n\">indent</span><span class=\"o\">=</span><span class=\"mi\">2</span><span class=\"p\">))</span>\n",
       "\n",
       "        <span class=\"n\">response</span> <span class=\"o\">=</span> <span class=\"n\">requests</span><span class=\"o\">.</span><span class=\"n\">post</span><span class=\"p\">(</span>\n",
       "            <span class=\"sa\">f</span><span class=\"s2\">&quot;</span><span class=\"si\">{</span><span class=\"n\">ollama_url</span><span class=\"si\">}</span><span class=\"s2\">/api/generate&quot;</span><span class=\"p\">,</span>\n",
       "            <span class=\"n\">json</span><span class=\"o\">=</span><span class=\"p\">{</span>\n",
       "                <span class=\"s2\">&quot;model&quot;</span><span class=\"p\">:</span> <span class=\"n\">model</span><span class=\"p\">,</span>\n",
       "                <span class=\"s2\">&quot;prompt&quot;</span><span class=\"p\">:</span> <span class=\"n\">prompt</span><span class=\"p\">,</span>\n",
       "                <span class=\"s2\">&quot;stream&quot;</span><span class=\"p\">:</span> <span class=\"kc\">False</span><span class=\"p\">,</span>\n",
       "            <span class=\"p\">},</span>\n",
       "            <span class=\"n\">timeout</span><span class=\"o\">=</span><span class=\"mi\">120</span><span class=\"p\">,</span>\n",
       "        <span class=\"p\">)</span>\n",
       "        <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">raise_for_status</span><span class=\"p\">()</span>\n",
       "\n",
       "        <span class=\"n\">response_text</span> <span class=\"o\">=</span> <span class=\"n\">response</span><span class=\"o\">.</span><span class=\"n\">json</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s2\">&quot;response&quot;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;&quot;</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">batch_results</span> <span class=\"o\">=</span> <span class=\"n\">json</span><span class=\"o\">.</span><span class=\"n\">loads</span><span class=\"p\">(</span><span class=\"n\">response_text</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">results</span><span class=\"o\">.</span><span class=\"n\">extend</span><span class=\"p\">(</span><span class=\"n\">batch_results</span><span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">return</span> <span class=\"n\">pd</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span><span class=\"p\">(</span><span class=\"n\">results</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k}{def}\\PY{+w}{ }\\PY{n+nf}{simulate\\PYZus{}product\\PYZus{}details\\PYZus{}ollama}\\PY{p}{(}\n",
       "    \\PY{n}{products\\PYZus{}df}\\PY{p}{:} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{DataFrame}\\PY{p}{,}\n",
       "    \\PY{n}{model}\\PY{p}{:} \\PY{n+nb}{str} \\PY{o}{=} \\PY{n}{DEFAULT\\PYZus{}MODEL}\\PY{p}{,}\n",
       "    \\PY{n}{ollama\\PYZus{}url}\\PY{p}{:} \\PY{n+nb}{str} \\PY{o}{=} \\PY{n}{OLLAMA\\PYZus{}URL}\\PY{p}{,}\n",
       "    \\PY{n}{prompt\\PYZus{}path}\\PY{p}{:} \\PY{n+nb}{str} \\PY{o}{=} \\PY{k+kc}{None}\\PY{p}{,}\n",
       "\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{DataFrame}\\PY{p}{:}\n",
       "\\PY{+w}{    }\\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}Generate product details using Ollama (local LLM).}\n",
       "\n",
       "\\PY{l+s+sd}{    Args:}\n",
       "\\PY{l+s+sd}{        products\\PYZus{}df: Input products with asin, category, price}\n",
       "\\PY{l+s+sd}{        model: Ollama model to use (default: llama3.2)}\n",
       "\\PY{l+s+sd}{        ollama\\PYZus{}url: Ollama API URL (default: http://localhost:11434)}\n",
       "\\PY{l+s+sd}{        prompt\\PYZus{}path: Optional path to custom prompt template file.}\n",
       "\\PY{l+s+sd}{            Template should contain \\PYZob{}products\\PYZus{}json\\PYZcb{} placeholder.}\n",
       "\n",
       "\\PY{l+s+sd}{    Returns:}\n",
       "\\PY{l+s+sd}{        DataFrame with added title, description, brand, features}\n",
       "\\PY{l+s+sd}{    \\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "    \\PY{c+c1}{\\PYZsh{} Load custom prompt or use default}\n",
       "    \\PY{n}{prompt\\PYZus{}template} \\PY{o}{=} \\PY{n}{\\PYZus{}load\\PYZus{}prompt\\PYZus{}template}\\PY{p}{(}\\PY{n}{prompt\\PYZus{}path}\\PY{p}{)} \\PY{k}{if} \\PY{n}{prompt\\PYZus{}path} \\PY{k}{else} \\PY{n}{PROMPT\\PYZus{}TEMPLATE}\n",
       "\n",
       "    \\PY{n}{results} \\PY{o}{=} \\PY{p}{[}\\PY{p}{]}\n",
       "    \\PY{n}{products} \\PY{o}{=} \\PY{n}{products\\PYZus{}df}\\PY{o}{.}\\PY{n}{to\\PYZus{}dict}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{records}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{for} \\PY{n}{i} \\PY{o+ow}{in} \\PY{n+nb}{range}\\PY{p}{(}\\PY{l+m+mi}{0}\\PY{p}{,} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{products}\\PY{p}{)}\\PY{p}{,} \\PY{n}{DEFAULT\\PYZus{}BATCH\\PYZus{}SIZE}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{batch} \\PY{o}{=} \\PY{n}{products}\\PY{p}{[}\\PY{n}{i} \\PY{p}{:} \\PY{n}{i} \\PY{o}{+} \\PY{n}{DEFAULT\\PYZus{}BATCH\\PYZus{}SIZE}\\PY{p}{]}\n",
       "        \\PY{n}{prompt} \\PY{o}{=} \\PY{n}{prompt\\PYZus{}template}\\PY{o}{.}\\PY{n}{format}\\PY{p}{(}\\PY{n}{products\\PYZus{}json}\\PY{o}{=}\\PY{n}{json}\\PY{o}{.}\\PY{n}{dumps}\\PY{p}{(}\\PY{n}{batch}\\PY{p}{,} \\PY{n}{indent}\\PY{o}{=}\\PY{l+m+mi}{2}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "        \\PY{n}{response} \\PY{o}{=} \\PY{n}{requests}\\PY{o}{.}\\PY{n}{post}\\PY{p}{(}\n",
       "            \\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+si}{\\PYZob{}}\\PY{n}{ollama\\PYZus{}url}\\PY{l+s+si}{\\PYZcb{}}\\PY{l+s+s2}{/api/generate}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "            \\PY{n}{json}\\PY{o}{=}\\PY{p}{\\PYZob{}}\n",
       "                \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{model}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{n}{model}\\PY{p}{,}\n",
       "                \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{prompt}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{n}{prompt}\\PY{p}{,}\n",
       "                \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{stream}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:} \\PY{k+kc}{False}\\PY{p}{,}\n",
       "            \\PY{p}{\\PYZcb{}}\\PY{p}{,}\n",
       "            \\PY{n}{timeout}\\PY{o}{=}\\PY{l+m+mi}{120}\\PY{p}{,}\n",
       "        \\PY{p}{)}\n",
       "        \\PY{n}{response}\\PY{o}{.}\\PY{n}{raise\\PYZus{}for\\PYZus{}status}\\PY{p}{(}\\PY{p}{)}\n",
       "\n",
       "        \\PY{n}{response\\PYZus{}text} \\PY{o}{=} \\PY{n}{response}\\PY{o}{.}\\PY{n}{json}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{get}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{response}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "        \\PY{n}{batch\\PYZus{}results} \\PY{o}{=} \\PY{n}{json}\\PY{o}{.}\\PY{n}{loads}\\PY{p}{(}\\PY{n}{response\\PYZus{}text}\\PY{p}{)}\n",
       "        \\PY{n}{results}\\PY{o}{.}\\PY{n}{extend}\\PY{p}{(}\\PY{n}{batch\\PYZus{}results}\\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{return} \\PY{n}{pd}\\PY{o}{.}\\PY{n}{DataFrame}\\PY{p}{(}\\PY{n}{results}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "def simulate_product_details_ollama(\n",
       "    products_df: pd.DataFrame,\n",
       "    model: str = DEFAULT_MODEL,\n",
       "    ollama_url: str = OLLAMA_URL,\n",
       "    prompt_path: str = None,\n",
       ") -> pd.DataFrame:\n",
       "    \"\"\"Generate product details using Ollama (local LLM).\n",
       "\n",
       "    Args:\n",
       "        products_df: Input products with asin, category, price\n",
       "        model: Ollama model to use (default: llama3.2)\n",
       "        ollama_url: Ollama API URL (default: http://localhost:11434)\n",
       "        prompt_path: Optional path to custom prompt template file.\n",
       "            Template should contain {products_json} placeholder.\n",
       "\n",
       "    Returns:\n",
       "        DataFrame with added title, description, brand, features\n",
       "    \"\"\"\n",
       "    # Load custom prompt or use default\n",
       "    prompt_template = _load_prompt_template(prompt_path) if prompt_path else PROMPT_TEMPLATE\n",
       "\n",
       "    results = []\n",
       "    products = products_df.to_dict(\"records\")\n",
       "\n",
       "    for i in range(0, len(products), DEFAULT_BATCH_SIZE):\n",
       "        batch = products[i : i + DEFAULT_BATCH_SIZE]\n",
       "        prompt = prompt_template.format(products_json=json.dumps(batch, indent=2))\n",
       "\n",
       "        response = requests.post(\n",
       "            f\"{ollama_url}/api/generate\",\n",
       "            json={\n",
       "                \"model\": model,\n",
       "                \"prompt\": prompt,\n",
       "                \"stream\": False,\n",
       "            },\n",
       "            timeout=120,\n",
       "        )\n",
       "        response.raise_for_status()\n",
       "\n",
       "        response_text = response.json().get(\"response\", \"\")\n",
       "        batch_results = json.loads(response_text)\n",
       "        results.extend(batch_results)\n",
       "\n",
       "    return pd.DataFrame(results)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Code\n",
    "import inspect\n",
    "from online_retail_simulator.simulate.product_details_ollama import (\n",
    "    simulate_product_details_ollama,\n",
    ")\n",
    "\n",
    "Code(inspect.getsource(simulate_product_details_ollama), language=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "LUXURY\n",
      "======================================================================\n",
      "\n",
      "  Title: Elegant Silk Blend Blouse with Hand Embroidery\n",
      "  Brand: Aurum Couture\n",
      "  Description: Experience the art of luxury with our exquisite silk blend blouse, adorned with intricate hand embroidery that adds a touch of sophistication to any outfit.\n",
      "\n",
      "  Title: Exquisite 4K Smartwatch with Premium Materials\n",
      "  Brand: Prestige Watches\n",
      "  Description: Elevate your style and stay connected in style with our exceptional 4K smartwatch, crafted from premium materials that exude luxury and sophistication.\n"
     ]
    }
   ],
   "source": [
    "luxury_products = simulate_product_details_ollama(\n",
    "    sample_products, prompt_path=\"prompt_luxury.txt\"\n",
    ")\n",
    "print_product_details(luxury_products, \"Luxury\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb45e138-20bd-4e22-9cdf-3db1df30a362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "BUDGET\n",
      "======================================================================\n",
      "\n",
      "  Title: Affordable Fashion - Women's Blouse Set (3-Piece)\n",
      "  Brand: Primark\n",
      "  Description: Stay stylish and comfortable with this versatile blouse set, perfect for work or everyday wear.\n",
      "\n",
      "  Title: Budget-Friendly Power Bank - 20,000mAh Portable Charger\n",
      "  Brand: Aukey\n",
      "  Description: Stay charged on-the-go with this affordable and reliable portable power bank.\n"
     ]
    }
   ],
   "source": [
    "budget_products = simulate_product_details_ollama(\n",
    "    sample_products, prompt_path=\"prompt_budget.txt\"\n",
    ")\n",
    "print_product_details(budget_products, \"Budget\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "The same product generates completely different content depending on the prompt—enabling A/B testing of content strategies, audience targeting, and channel customization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
