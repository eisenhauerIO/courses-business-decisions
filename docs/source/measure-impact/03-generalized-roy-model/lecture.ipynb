{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04916c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# from auxiliary import monte_carlo, plot_est_mte, process_data\n",
    "# from IPython.display import HTML, display\n",
    "# from pylab import rcParams\n",
    "# from scipy.stats import norm\n",
    "# from tutorial_semipar_auxiliary import plot_semipar_mte\n",
    "\n",
    "# import grmpy\n",
    "# from grmpy.read.read import read\n",
    "\n",
    "# rcParams[\"figure.figsize\"] = 15, 10\n",
    "# rcParams[\"font.size\"] = 18\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "# display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bb7f66",
   "metadata": {},
   "source": [
    "\n",
    "# The *grmpy*  package \n",
    "This notebook demonstrates the current capabilities of the *grmpy* package. *grmpy* is an open source package for the programming language python that enables researchers to simulate datasets andestimate parameters using already existing data within the structure of the generalized Roy model. Currently the package serves as a teaching tool for a course on the econometrics of policy evaluation at the University of Bonn. The corresponding lecture materials can be found on [GitHub](https://github.com/HumanCapitalAnalysis/econometrics).  Morover it is thought of as a promotion for the conceptual framework as well as a showcase for basic software engineering practices.\n",
    "\n",
    "For a more detailed overview on the economic background as well as the installation routine feel free to take a look on the [online documentation](https://grmpy.readthedocs.io/en/develop/).\n",
    "\n",
    "The notebook itself is divided in three parts. Firstly we provide a basic outline on how to use the package and introduce the core features. Next we will show that the results obtained by the package's estimation process withstand a critical examination by comparing its performance in the presence of essential heterogeneity with several other estimation approaches like Ordinary Least Squares and Instrumental variables. We conclude by conducting a replication of results from   \n",
    "\n",
    "Carneiro, P., Heckman, J. J., & Vytlacil, E. J. (2011). [Estimating marginal returns to education.](https://pubs.aeaweb.org/doi/pdfplus/10.1257/aer.101.6.2754)\n",
    "*American Economic Review, 101*(6), 2754-81.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ymt4b8ku3k",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "We build on the following main references:\n",
    "\n",
    "* James J. Heckman and Edward J. Vytlacil. Econometric evaluation of social programs, part I: Causal models, structural models and econometric policy evaluation. In *Handbook of Econometrics*, volume 6B, chapter 70, pages 4779–4874. Elsevier Science, 2007.\n",
    "\n",
    "* James J. Heckman and Edward J. Vytlacil. Econometric evaluation of social programs, part II: Using the marginal treatment effect to organize alternative econometric estimators to evaluate social programs, and to forecast their effects in new environments. In *Handbook of Econometrics*, volume 6B, chapter 71, pages 4875–5143. Elsevier Science, 2007.\n",
    "\n",
    "* Jaap H. Abbring and James J. Heckman. Econometric evaluation of social programs, part III: Distributional treatment effects, dynamic treatment effects, dynamic discrete choice, and general equilibrium policy evaluation. In *Handbook of Econometrics*, volume 6B, chapter 72, pages 5145–5303. Elsevier Science, 2007."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9621b9eb",
   "metadata": {},
   "source": [
    "## General Framwork\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    " &\\textbf{Potential Outcomes} & & \\textbf{Choice}  &\\\\\n",
    " & Y_{1,i} = \\mu_1(X_i) + U_{1,i} &  &C_i = \\mu_C(Z_i) - V &\\\\\n",
    " & Y_{0,i} = \\mu_0(X_i) + U_{0,i} &  & D_i = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & if \\ C_i > 0 \\\\\n",
    "0 &  \\text{otherwise}\\\\\n",
    "\\end{array}\n",
    "\\right.  &\\\\\n",
    "&&&&\\\\\n",
    "&\\textbf{Distributional Characteristics}&&&\\\\\n",
    "&\\{U_{1}, U_{0}, V\\} \\sim \\left(0, \\Sigma\\right)&&&\\\\\n",
    "&&&&\\\\\n",
    "& \\textbf{Observed Outcome} &&&\\\\\n",
    "& Y_i = D_i Y_{1,i} + (1-D_i) Y_{0,i} &&&\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "#### Choice Process\n",
    "- $Z_i$ captures all observable factors that affect the decision of an individual to select itself into treatment\n",
    "\n",
    "\n",
    "- $V_i$ denotes (from perspective of the econometrician) unobservable components that drive the selection decision (Note: V enters with a negative sign $\\Rightarrow$ conditional on $Z_i$, high values of $V_i$ indicate a lower propensity to select into treatment\n",
    "\n",
    "\n",
    "- $C_i$ is the latent propensity indicator of individual $i$ \n",
    "\n",
    "\n",
    "- $D_i$ indicates whether an individual selects itself in the treatment group\n",
    "\n",
    "\n",
    "- Furthermore we can rearrange $D_i$ s.t. the individual selects into treatment if\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&\\;\\mu_C(Z_i) > V_i\\\\\n",
    "\\Leftrightarrow&\\;F_V(\\mu_C(Z_i)) > F_V(V_i)\\\\\n",
    "&\\\\\n",
    " \\Rightarrow& \\; D_i = \\mathbb{1}\\{F_V(\\mu_C(Z_i)) > F_V(V_i)\\}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- $F_V(\\mu_C(Z_i))$: Probability of being treated given an individual's observable characteristics (propensity score)\n",
    "\n",
    "\n",
    "- $F_V(V_i)$: The quantile of $V$'s distribution the individual's realization $V_i$ is located in\n",
    "\n",
    "**$\\Rightarrow$ The individuals select themselves into treatment when their propensity score outruns the quantile of the distribution $V_i$**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Outcomes\n",
    "- $(Y_{1,i}, Y_{0,i})$ denotes the set of potential outcomes of individual $i$\n",
    "\n",
    "\n",
    "- $Y_i$ denotes the observable outcome of individual $i$\n",
    "\n",
    "\n",
    "- Rearranging the outcome equation leads to:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "Y_i = Y_{0,i} + D_i \\underbrace{(Y_{1,i} - Y_{0,i})}_{\\Delta_i}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- $\\Delta_i$ : Causal effect of treatment for individual $i$\n",
    "\n",
    "**Evaluation Problem**\n",
    "\n",
    "The set of equations above entails one of the most crucial challenges for the evaluation of policy interventions. We as researchers are not able to observe the potential outcome space for an individual but instead we observe either $Y_{1,i}$ or $Y_{0,i}$ for one and the same individual dependent on the individual's selection decision. This is referred to as the **evaluation problem**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e4aa66",
   "metadata": {},
   "source": [
    "## Heterogeneity\n",
    "Central question in all econometrics of policy analysis:\n",
    "\n",
    "_What gives rise to variation and outcomes among, from the econometrician’s perspective, otherwise identical agents?_ (Heckman 2001)\n",
    "\n",
    "**Answer: Heterogeneity**\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Delta_i = Y_{1,i} - Y_{0,i} = \\underbrace{\\mu_1(X_i) - \\mu_0(X_i)}_{\\text{average effect}} + \\underbrace{U_{1,i} -U_{0,i}}_{\\text{individual specific effect}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- **Observable heterogeneity:** \n",
    "\n",
    "    * Is reflected by the first term of the equation.\n",
    "    \n",
    "    * Denotes the differences between individuals, which are based on differences in observable characteristics captured by $X_i$\n",
    "    \n",
    "    * Note that since we observe $X_i$, we are able to ćondition on it\n",
    "    \n",
    "    \n",
    "- **Unobservable heterogeneity:**\n",
    "    * Represented by the difference in the unobservables.\n",
    "    * Note: The term *unobservable* does not imply that $U_{1,i}$ and $U_{0,i}$ are completely excluded in an individual's information set. \n",
    "\n",
    "**Question: When does unobservable heterogeneity pose problems in the analysis of average effect parameters?**\n",
    "\n",
    "\n",
    "**Answer: If the individual's selection process depends on unobservable \"gains\" we have a selection problem.**\n",
    "\n",
    "\n",
    "This kind of heterogeneity is referred to as **essential heterogeneity** \n",
    "* The reaction on interventions are heterogeneous among individuals\n",
    "\n",
    "* Individuals select their treatment state with at least partly knowledge of their own responses to treatment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1358e5fe",
   "metadata": {},
   "source": [
    "## Parameters of Interest\n",
    "\n",
    "- In a perfect world we as economists would focus on determining $\\Delta_i$. In reality this is impossible due to the aformentioned evaluation problem!\n",
    "\n",
    "\n",
    "- For this reason, the analysis of conventional treatment effect analysis is confined to the identification of average effects for specific subgroups. \n",
    "\n",
    "- The common subgroups are the whole population ($\\Delta^{ATE}$), the treated ($\\Delta^{TT}$) or the untreated share ($\\Delta^{TUT}$). The effects are characterized by the following equations\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    " \\Delta^{ATE} &= E[Y_1 -Y_0] \\\\\n",
    " \\Delta^{TT}\\;\\; &= E[Y_1 -Y_0|D=1]\\\\\n",
    " \\Delta^{TUT} &= E[Y_1 -Y_0|D=0]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- When treatment is randomly assigned or the selection is not based on the potential outcomes there is no significant difference between the average individuals with different treatment states.\n",
    "\n",
    "\n",
    "- Therefore all effects are identical! And we can substitute $E[Y_1]$ and $E[Y_0]$ with the observed average outcomes $E[Y|D=1]$ and $E[Y|D=0]$.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    " \\Delta^{ATE} =  \\Delta^{TUT} =  \\Delta^{TT} = E[Y|D=1] - E[Y|D=0]\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926ec262",
   "metadata": {},
   "source": [
    "## Illustration\n",
    "\n",
    "For reasons of simplicity I will make use of the normal-linear-in-parameters version generalized Roy model. In addition we assume that the unobservable terms $\\{U_1, U_0, V\\}$ are normally distributed according to the covariance matrix $\\Sigma$. The following set of equations characterize the underlying model:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    " &\\textbf{Potential Outcomes} & & \\textbf{Choice}  &\\\\\n",
    " & Y_1 = \\beta_1 X + U_{1} &  &D_i = \\mathbf{1}\\{\\Phi(\\gamma Z) > u_D\\} &\\\\\n",
    " & Y_0 = \\beta_0 X + U_{0} &  & \\text{with $u_D = \\Phi(V)$}  &\\\\\n",
    "&&&&\\\\\n",
    "&\\textbf{Distributional Characteristics}&&&\\\\\n",
    "&\\{U_{1}, U_{0}, V\\} \\sim \\mathcal{N}\\left(0, \\Sigma\\right)&&\\Sigma =  \\begin{bmatrix}\n",
    "    \\sigma_1^{2} & \\sigma_{1,0} & \\sigma_{1,V} \\\\\n",
    "    \\sigma_{1,0} & \\sigma_0^{2} & \\sigma_{0,V} \\\\\n",
    "    \\sigma_{1,V} & \\sigma_{0,V} & \\sigma_V^{2} \\\\\n",
    "  \\end{bmatrix}&\\\\\n",
    "&&&&\\\\\n",
    "& \\textbf{Observed Outcome} &&&\\\\\n",
    "& Y = D Y_1 + (1-D) Y_0 &&&\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eda73a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%file files/no_eh.grmpy.yml\n",
    "# ---\n",
    "# SIMULATION:\n",
    "#     agents: 10000\n",
    "#     seed: 2356\n",
    "#     source: data\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8244a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = grmpy.simulate(\"files/no_eh.grmpy.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4937e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a376ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicator = df.D == 1\n",
    "# Delta = df[\"Y1\"] - df[\"Y0\"]\n",
    "# ATE = np.mean(df[\"Y1\"] - df[\"Y0\"])\n",
    "# TT = np.mean(df[indicator][\"Y1\"] - df[indicator][\"Y0\"])\n",
    "# TUT = np.mean(df[~indicator][\"Y1\"] - df[~indicator][\"Y0\"])\n",
    "\n",
    "# effect_est = np.mean(df[indicator][\"Y\"]) - np.mean(df[~indicator][\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd7dfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set up figure object\n",
    "# ax = plt.figure(figsize=(15, 10))\n",
    "# plt.ylabel(\"$f_{Y_1 - Y_0}$\", fontsize=20)\n",
    "# plt.xlabel(\"$Y_1 - Y_0$\", fontsize=20)\n",
    "# plt.axis([-1, 2, 0.0, 1.31])\n",
    "\n",
    "# # plot distribution of individual effects\n",
    "# sns.distplot(Delta, kde=True, hist=False)\n",
    "\n",
    "# # plot average effect parameters\n",
    "# plt.plot([ATE, ATE], [0.00, 1.3], label=r\"$\\Delta^{ATE}$\")\n",
    "# plt.plot([TT, TT], [0.00, 1.3], label=r\"$\\Delta^{TT}$\")\n",
    "# plt.plot([TUT, TUT], [0.00, 1.3], label=r\"$\\Delta^{TUT}$\")\n",
    "# plt.plot([effect_est, effect_est], [0.00, 1.3], label=r\"$\\hat{\\Delta}$\")\n",
    "\n",
    "\n",
    "# plt.legend(prop={\"size\": 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5735145",
   "metadata": {},
   "source": [
    "- The figure should not lead to the false assumptions that all introduced parameters measure the same effect.\n",
    "\n",
    "- If individuals select themselves into treatment based on outcome related characteristics (the potential outcomes $Y_1, Y_0$ are no longer independent of the treatment status $D$), we can observe differences between the parameters.\n",
    "\n",
    "- These differences are linked to the selection process. Unlike in the abscence of essential heterogeneity, individuals who select themselves into treatment differ inherently from individuals who do not in respect of their unobservable characteristics.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "E[Y_1|D=1] - E[Y_0|D=0] = \\underbrace{E[Y_1-Y_0]}_{\\Delta^{ATE}} + \\underbrace{E[Y_1 -Y_0|D=1] - E[Y_1-Y_0]}_{\\text{selection on gains}} + \\underbrace{E[Y_0|D=1] - E[Y_0|D=0]}_{\\text{selection on endowments}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The bias can be decomposed in two different components:\n",
    "\n",
    "\n",
    "**Selection on endowment bias**  \n",
    "As indicated by the equation above, differences in endowments ($Y_0$) between treated and untreated individuals lead to a bias. This reflects that there exist difference in outcomes between the treated and untreated share of the population even without the treatment. \n",
    "\n",
    "\n",
    "**Selection on gains bias**  \n",
    "The selection on gains bias illustrates that the average benefit for individuals who select themselves into treatment differs from the effect of treatment that do not. \n",
    "\n",
    "\n",
    "\n",
    "**NOTE:** The type of bias depends on the parameter of interest for which the effect should be measured.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fffadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%file files/eh.grmpy.yml\n",
    "# ---\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d0bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_eh = grmpy.simulate(\"files/eh.grmpy.yml\")\n",
    "# df_eh.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4336e5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicator = df_eh.D == 1\n",
    "# Delta = df_eh[\"Y1\"] - df_eh[\"Y0\"]\n",
    "# ATE = np.mean(df_eh[\"Y1\"] - df_eh[\"Y0\"])\n",
    "# TT = np.mean(df_eh[indicator][\"Y1\"] - df_eh[indicator][\"Y0\"])\n",
    "# TUT = np.mean(df_eh[~indicator][\"Y1\"] - df_eh[~indicator][\"Y0\"])\n",
    "\n",
    "# effect_estimate = np.mean(df_eh[indicator][\"Y\"]) - np.mean(df_eh[~indicator][\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6577412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set up figure object\n",
    "# ax = plt.figure(figsize=(15, 10))\n",
    "# plt.ylabel(\"$f_{Y_1 - Y_0}$\", fontsize=20)\n",
    "# plt.xlabel(\"$Y_1 - Y_0$\", fontsize=20)\n",
    "# plt.axis([-1, 2, 0.0, 1.31])\n",
    "\n",
    "# # plot distribution of individual effects\n",
    "# sns.distplot(Delta, kde=True, hist=False)\n",
    "\n",
    "# # plot average effect parameters\n",
    "# plt.plot([ATE, ATE], [0.00, 1.3], label=r\"$\\Delta^{ATE}$\")\n",
    "# plt.plot([TT, TT], [0.00, 1.3], label=r\"$\\Delta^{TT}$\")\n",
    "# plt.plot([TUT, TUT], [0.00, 1.3], label=r\"$\\Delta^{TUT}$\")\n",
    "# plt.plot([effect_estimate, effect_estimate], [0.00, 1.3], label=r\"$\\hat{\\Delta}$\")\n",
    "\n",
    "\n",
    "# plt.legend(prop={\"size\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5ab5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g1 = sns.jointplot(x=df[\"V\"], y=df[\"U1\"], height=10).set_axis_labels(\"$V$\", \"$U_1$\", fontsize=18)\n",
    "# g1.fig.subplots_adjust(top=0.9)\n",
    "# g1.fig.suptitle(\"Abscence of essential heterogeneity\", fontsize=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefa201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g2 = sns.jointplot(x=df_eh[\"V\"], y=df_eh[\"U1\"], height=10).set_axis_labels(\"$V$\", \"$U_1$\", fontsize=20)\n",
    "# g2.fig.subplots_adjust(top=0.9)\n",
    "# g2.fig.suptitle(\"Presence of essential heterogeneity\", fontsize=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e655f1",
   "metadata": {},
   "source": [
    "## The Marginal Treatment Effect\n",
    "\n",
    "- The concept was first introduced by Björklund & Moffitt (1987) and advanced by a broad variety of papers by Heckman & Vytlacil (1999, 2001, 2005, 2007)\n",
    "\n",
    "- It is defined as the effect of treatment for individuals who are indifferent between taking the treatment and not. In terms of the Roy model framework it is characterized by the following equation\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Delta^{MTE}(x,u_D) = E[Y_1 -Y_0|X=x, U_D=u_D]\\\\\n",
    "\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "- It can be interpreted as the *willingness to pay* for treatment participation of individuals with characteristics $Z_i=z$ at the margin\n",
    "\n",
    "\n",
    "- **Note:** Instead of explicitly assigning one value to a given policy intervention, $\\Delta^{MTE}$ provides a continuum of effects along the distribution of the unobservable variable $V$\n",
    "\n",
    "\n",
    "- $V_i$ enters the choice function $D_i$ with a negative sign $\\Rightarrow$ Individuals with $U_D$ close to zero are most likely to select themselves into treatment.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d151e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import init specifications\n",
    "# spec = read(\"files/no_eh.grmpy.yml\")\n",
    "# spec_eh = read(\"files/eh.grmpy.yml\")\n",
    "\n",
    "# # set up a figure object\n",
    "# ax = plt.figure(figsize=(15, 10))\n",
    "\n",
    "# plt.ylabel(r\"$\\Delta^{MTE}$\", fontsize=24)\n",
    "# plt.xlabel(\"$u_D$\", fontsize=24)\n",
    "\n",
    "# labels = [\"Without essential heterogeneity\", \"With essential heterogeneity\"]\n",
    "# colors = [\"blue\", \"orange\"]\n",
    "# datasets = [df, df_eh]\n",
    "\n",
    "# for counter, init_dict in enumerate([spec, spec_eh]):\n",
    "#     # assign parameters\n",
    "#     beta1 = init_dict[\"TREATED\"][\"params\"]\n",
    "#     beta0 = init_dict[\"UNTREATED\"][\"params\"]\n",
    "#     cov1V = init_dict[\"DIST\"][\"params\"][2]\n",
    "#     cov0V = init_dict[\"DIST\"][\"params\"][4]\n",
    "\n",
    "#     # define relevant dataset\n",
    "#     data = datasets[counter]\n",
    "\n",
    "#     covariates = init_dict[\"TREATED\"][\"order\"]\n",
    "#     X = np.mean(data[covariates])\n",
    "\n",
    "#     quantiles = np.arange(0.01, 1.0, 0.01)\n",
    "\n",
    "#     mte = np.dot(X, beta1 - beta0) + (cov1V - cov0V) * norm.ppf(quantiles)\n",
    "#     plt.plot(quantiles, mte, label=labels[counter], color=colors[counter], linewidth=4)\n",
    "\n",
    "\n",
    "# plt.legend(prop={\"size\": 20})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfef4373",
   "metadata": {},
   "source": [
    "- $\\Delta^{MTE}$ is constant in the absence of essential heterogeneity whereas decreasing respectively increasing values indicate the presence of essential heterogeneity. Why?\n",
    "\n",
    "- Additionally whether $\\Delta^{MTE}$ is increasing or decreasing along $u_D$ provides information about which kind of selection on gains take place\n",
    "\n",
    "- In addition it is also possible to derive all conventional effects from $\\Delta^{MTE}$ by applying effect specific weights along the distribution of $V$:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\omega^{ATE}(x,u_D) &= 1.0\\\\\n",
    "\\omega^{TT}(x,u_D) &= \\frac{\\int_{u_D}^{1}f(p|X=x)dp}{E[P|X=x]}\\\\\n",
    "\\omega^{TUT}(x,u_D) &= \\frac{\\int_{0}^{u_D}f(p|X=x)dp}{E[1-P|X=x]}\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Formally:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Delta^j = \\int_0^1 \\omega_j(x,u_D) \\Delta^{MTE}(x,u_D)du_D\\\\\n",
    "\\text{ for } j = \\text{ ATE, TT, TUT}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef57bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # assign parameter and choice covariates\n",
    "# gamma = spec_eh[\"CHOICE\"][\"params\"]\n",
    "# Z = df_eh[spec_eh[\"CHOICE\"][\"order\"]]\n",
    "\n",
    "# # compute average propensity score as well as individual propensity score\n",
    "# propensity_mean = np.mean(norm.cdf(np.dot(gamma, Z.T)))\n",
    "# auxiliary = norm.cdf(np.dot(gamma, Z.T))\n",
    "\n",
    "# # compute the integral\n",
    "# integral_TT = np.array([sum(auxiliary > quantiles[i]) / Z.shape[0] for i in range(len(quantiles))])\n",
    "# integral_TUT = np.array([1 - (sum(auxiliary > quantiles[i]) / Z.shape[0]) for i in range(len(quantiles))])\n",
    "\n",
    "# # compute the weights\n",
    "# omega_TT = integral_TT / propensity_mean\n",
    "# omega_TUT = integral_TUT / (1 - propensity_mean)\n",
    "# omega_ATE = [1.0] * len(quantiles)\n",
    "\n",
    "\n",
    "# # plot\n",
    "# ax1 = plt.figure(figsize=(15, 10)).add_subplot(111)\n",
    "\n",
    "# plt.ylabel(r\"$\\Delta^{MTE}$\", fontsize=24)\n",
    "# plt.xlabel(\"$u_D$\", fontsize=24)\n",
    "# ax1.plot(quantiles, mte, color=\"blue\", label=r\" $\\Delta^{MTE}$\", linewidth=3.0)\n",
    "# ax2 = ax1.twinx()\n",
    "\n",
    "\n",
    "# ax2.plot(\n",
    "#     quantiles,\n",
    "#     omega_TT,\n",
    "#     color=\"red\",\n",
    "#     linestyle=\"--\",\n",
    "#     label=r\" $\\omega^{TT}$\",\n",
    "#     linewidth=3.0,\n",
    "# )\n",
    "\n",
    "# ax2.plot(\n",
    "#     quantiles,\n",
    "#     omega_TUT,\n",
    "#     color=\"green\",\n",
    "#     linestyle=\"--\",\n",
    "#     label=r\" $\\omega^{TUT}$\",\n",
    "#     linewidth=3.0,\n",
    "# )\n",
    "\n",
    "# ax2.plot(\n",
    "#     quantiles,\n",
    "#     omega_ATE,\n",
    "#     color=\"orange\",\n",
    "#     linestyle=\"-.\",\n",
    "#     label=r\" $\\omega^{ATE}$\",\n",
    "#     linewidth=3.0,\n",
    "# )\n",
    "\n",
    "# plt.legend(prop={\"size\": 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad15479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string = (\n",
    "#     \"      True Values  Weighted Values\\n\\n\"\n",
    "#     \"ATE:{0:>10.5f}{3:>15.5f}\\nTT:{1:>11.5f}{4:>15.5f}\\nTUT:{2:>10.5f}{5:>15.5f}\"\n",
    "# )\n",
    "\n",
    "# # Apply weights to the mte\n",
    "# ATE_w = np.mean(np.multiply(np.array(mte), omega_ATE))\n",
    "# TT_w = np.mean(np.multiply(np.array(mte), omega_TT))\n",
    "# TUT_w = np.mean(np.multiply(np.array(mte), omega_TUT))\n",
    "# effects = [ATE, TT, TUT, ATE_w, TT_w, TUT_w]\n",
    "\n",
    "# # print comparison to the true values\n",
    "# print(string.format(*effects))\n",
    "\n",
    "# print(\"\\n\\n\\nNaive comparison: {:.5f}\".format(effect_estimate))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb59ba17",
   "metadata": {},
   "source": [
    "### Link to Local Average Treatment Effect\n",
    "\n",
    "- The concept of the marginal treatment effect is closely related to the local average treatment effect ($\\Delta^{LATE}$)\n",
    "\n",
    "\n",
    "- More specifically, it can be shown that $\\Delta^{LATE}$ converges to $\\Delta^{MTE}$. It can be represented as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Delta^{LATE}(u_D, u^{'}_D x) = E[Y_1 -Y_0| u_D > U_D > u^{'}_D, X=x]\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "- where $u_D$  and $u'_D$ are defined as the propensity scores for $Z=z$ and $Z= z'$ or equivalent as point in the unit interval of the distribution of $V$\n",
    "\n",
    "\n",
    "- Taking the limit of $\\Delta^{LATE}$ as $u_D$ approaches $u'_D$ reduced the equation above to the definition of  $\\Delta^{MTE}$.\n",
    "\n",
    "\n",
    "- Therefore  $\\Delta^{LATE}$ can be defined more generally as a function dependent of $\\Delta^{MTE}$:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\Delta^{LATE} = \\frac{1}{u_D - u'_D} \\int_0^1\\Delta^{MTE}(x,u_D) du_D\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc0c340",
   "metadata": {},
   "source": [
    "## Estimation via grmpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e83535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rslt = grmpy.fit(\"files/eh.grmpy.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd392de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cat 'files/eh.grmpy.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d5bcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rslt.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f529ea2",
   "metadata": {},
   "source": [
    "## Comparing estimation strategies\n",
    "\n",
    "- We will now compare different estimation strategies regarding their capability to evaluate the average effect of treatment in the presence of essential heterogeneity. \n",
    "\n",
    "\n",
    "- In particular we will compare results obtained by:  \n",
    "    - **Naive comparison**  \n",
    "    - **Ordinary Least Squares** \n",
    "    - **Instrumental Variables**  \n",
    "        - **Conventional IV**  \n",
    "        - **Local IV**  \n",
    "        \n",
    "        \n",
    "- For this purpose we will conduct a monte carlo simulation approach:\n",
    "    - We simulate a dataset of 10000 individuals \n",
    "    - Compute $\\mu_1(X_i)$, $\\mu_0(X_i)$, $\\mu_D(Z_i)$  for all individuals\n",
    "    - Each iteration of the monte calo simulation consists of three steps:\n",
    "        * We draw unobservable variables from a mutlivariate normal distribution with mean zero and covariance matrix $\\Sigma$, which has the following form\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\\\\n",
    "\\Sigma =  \\begin{bmatrix}\n",
    "    0.01 & 0 & \\frac{\\rho_{1,V}}{0.1}  \\\\\n",
    "    0 & 0.01 & 0 \\\\\n",
    "    \\frac{\\rho_{1,V}}{0.1}  & 0 & 1 \\\\\n",
    "  \\end{bmatrix}\n",
    "\\\\\n",
    "\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "        * Next we combine the simulated unobservable variables with $\\mu_1(X_i)$, $\\mu_0(X_i)$ and $\\mu_D(Z_i)$          \n",
    "        * During each step we conduct four estimations for the ATE\n",
    "        \n",
    "        \n",
    "- We will iterate over this process 10 times whereupon  the correlation between $U_1$ and $V$, captured by $\\rho_{1,V}$ increases during each iteration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grmpy.simulate(\"files/mc.grmpy.yml\")\n",
    "# monte_carlo(\"files/mc.grmpy.yml\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a62f47",
   "metadata": {},
   "source": [
    "# Replication Excerise "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05ac541",
   "metadata": {},
   "source": [
    "Next we will focus on reproducing the results for the marginal treatment effect by Carneiro et al. (2011). Due to reasons of privacy regarding local variables, we are not able to merge the data provided by the authors so that they fully coincide with the original data set. Therefore our replication setup makes use of a mock data set. For this purpose we randomly merge the individual specific data with the local characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8535558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic = pd.read_stata(\"data/basicvariables.dta\")\n",
    "# local = pd.read_stata(\"data/localvariables.dta\")\n",
    "# df = pd.concat([basic, local], axis=1)\n",
    "# process_data(df, \"data/aer-replication-mock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6066657",
   "metadata": {},
   "source": [
    "In the next step we have to create a inititalization file that fully coincides with the setup by Carneiro et. al. (2011). Therefore we use the information that the authors provide in their appendix to create the following init file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bfe353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%file files/replication.grmpy.yml\n",
    "# ---\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d3f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rslt = grmpy.fit(\"files/replication.grmpy.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9901014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mte = plot_est_mte(rslt, \"files/replication.grmpy.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99869399",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rslt = grmpy.fit(\"files/replication.grmpy.yml\", semipar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60a260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mte, quantiles = plot_semipar_mte(rslt, \"files/tutorial_semipar.yml\", nbootstraps=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b71da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
