{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Potential Outcomes Model\n",
    "\n",
    "> **Reference:** *Causal Inference: The Mixtape*, Chapter 4: Potential Outcomes Causal Model (pp. 119-174)\n",
    "\n",
    "This lecture introduces the potential outcome framework for causal inference. We apply these concepts using the Online Retail Simulator to answer: **What would be the effect on sales if we improved product content quality?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Part I: Theory\n",
    "\n",
    "This section covers the theoretical foundations of the potential outcome framework as presented in Cunningham's *Causal Inference: The Mixtape*, Chapter 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. The Potential Outcome Framework\n",
    "\n",
    "The potential outcome framework, also known as the **Rubin Causal Model (RCM)**, provides a precise mathematical language for defining causal effects. The framework was developed by Donald Rubin in the 1970s, building on earlier work by Jerzy Neyman.\n",
    "\n",
    "### Core Definitions\n",
    "\n",
    "For each unit $i$ in a population, we define:\n",
    "\n",
    "- $D_i \\in \\{0, 1\\}$: **Treatment indicator** (1 if unit receives treatment, 0 otherwise)\n",
    "- $Y_i^1$: **Potential outcome under treatment** — the outcome unit $i$ *would have* if treated\n",
    "- $Y_i^0$: **Potential outcome under control** — the outcome unit $i$ *would have* if not treated\n",
    "\n",
    "The key insight is that both potential outcomes exist conceptually for every unit, but we can only observe one of them.\n",
    "\n",
    "### The Switching Equation\n",
    "\n",
    "The **observed outcome** follows the switching equation:\n",
    "\n",
    "$$Y_i = D_i \\cdot Y_i^1 + (1 - D_i) \\cdot Y_i^0$$\n",
    "\n",
    "This equation formalizes which potential outcome we observe:\n",
    "- If $D_i = 1$ (treated): we observe $Y_i = Y_i^1$\n",
    "- If $D_i = 0$ (control): we observe $Y_i = Y_i^0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. The Fundamental Problem of Causal Inference\n",
    "\n",
    "Holland (1986) articulated what he called the *fundamental problem of causal inference*: **we cannot observe both potential outcomes for the same unit at the same time**.\n",
    "\n",
    "Consider this example:\n",
    "\n",
    "| Unit | Treatment | Observed | $Y^1$ | $Y^0$ |\n",
    "|------|-----------|----------|-------|-------|\n",
    "| A | Treated | \\$500 | \\$500 | ? |\n",
    "| B | Control | \\$300 | ? | \\$300 |\n",
    "| C | Treated | \\$450 | \\$450 | ? |\n",
    "| D | Control | \\$280 | ? | \\$280 |\n",
    "\n",
    "The question marks represent **counterfactuals** — outcomes that would have occurred under the alternative treatment assignment. These are fundamentally unobservable.\n",
    "\n",
    "This is not a data limitation that can be solved with more observations or better measurement. It is a logical impossibility: the same unit cannot simultaneously exist in both treatment states."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Individual Treatment Effects\n",
    "\n",
    "The **individual treatment effect (ITE)** for unit $i$ is defined as:\n",
    "\n",
    "$$\\delta_i = Y_i^1 - Y_i^0$$\n",
    "\n",
    "This measures how much unit $i$'s outcome would change due to treatment.\n",
    "\n",
    "**Key insight:** Because we can never observe both $Y_i^1$ and $Y_i^0$ for the same unit, individual treatment effects are fundamentally unidentifiable. This is why causal inference focuses on *population-level* parameters instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Population-Level Parameters\n",
    "\n",
    "Since individual effects are unobservable, we focus on population averages:\n",
    "\n",
    "| Parameter | Definition | Interpretation |\n",
    "|-----------|------------|----------------|\n",
    "| **ATE** | $E[Y^1 - Y^0]$ | Average effect across *all* units |\n",
    "| **ATT** | $E[Y^1 - Y^0 \\mid D=1]$ | Average effect among units that *were* treated |\n",
    "| **ATC** | $E[Y^1 - Y^0 \\mid D=0]$ | Average effect among units that *were not* treated |\n",
    "\n",
    "### When Do These Differ?\n",
    "\n",
    "If treatment effects are **homogeneous** (same for everyone), then $\\text{ATE} = \\text{ATT} = \\text{ATC}$.\n",
    "\n",
    "If treatment effects are **heterogeneous** and correlated with treatment selection, these parameters will differ. For example, if high-ability workers are more likely to get job training *and* benefit more from it, then $\\text{ATT} > \\text{ATE}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. The Naive Estimator and Selection Bias\n",
    "\n",
    "The most intuitive approach to estimating causal effects is the **naive estimator** (also called the simple difference in means):\n",
    "\n",
    "$$\\hat{\\delta}_{\\text{naive}} = E[Y \\mid D=1] - E[Y \\mid D=0]$$\n",
    "\n",
    "This compares average outcomes between treated and control groups. When does this equal the ATE?\n",
    "\n",
    "### Decomposing the Naive Estimator\n",
    "\n",
    "We can decompose the naive estimator as follows:\n",
    "\n",
    "$$E[Y \\mid D=1] - E[Y \\mid D=0] = \\underbrace{E[Y^1 - Y^0]}_{\\text{ATE}} + \\underbrace{E[Y^0 \\mid D=1] - E[Y^0 \\mid D=0]}_{\\text{Selection Bias}}$$\n",
    "\n",
    "The naive estimator equals the ATE only when **selection bias is zero**.\n",
    "\n",
    "### What Causes Selection Bias?\n",
    "\n",
    "Selection bias occurs when treatment assignment is correlated with potential outcomes:\n",
    "\n",
    "$$\\text{Selection Bias} = E[Y^0 \\mid D=1] - E[Y^0 \\mid D=0] \\neq 0$$\n",
    "\n",
    "This happens when treated units would have had *different* outcomes than control units *even without treatment*.\n",
    "\n",
    "### Full Bias Decomposition (with Heterogeneous Effects)\n",
    "\n",
    "When treatment effects vary across units, the full decomposition is:\n",
    "\n",
    "$$\\hat{\\delta}_{\\text{naive}} - \\text{ATE} = \\underbrace{E[Y^0 \\mid D=1] - E[Y^0 \\mid D=0]}_{\\text{Baseline Bias}} + \\underbrace{E[\\delta \\mid D=1] - E[\\delta]}_{\\text{Differential Treatment Effect Bias}}$$\n",
    "\n",
    "- **Baseline bias**: Treated units have different baseline outcomes\n",
    "- **Differential treatment effect bias**: Treated units have different treatment effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6. Randomization: The Gold Standard\n",
    "\n",
    "**Randomized controlled trials (RCTs)** solve the selection bias problem by ensuring treatment is assigned independently of potential outcomes.\n",
    "\n",
    "### Independence Assumption\n",
    "\n",
    "Under randomization:\n",
    "\n",
    "$$(Y^1, Y^0) \\perp\\!\\!\\!\\perp D$$\n",
    "\n",
    "This means potential outcomes are statistically independent of treatment assignment.\n",
    "\n",
    "### Why Randomization Works\n",
    "\n",
    "Under independence:\n",
    "\n",
    "$$E[Y^0 \\mid D=1] = E[Y^0 \\mid D=0] = E[Y^0]$$\n",
    "$$E[Y^1 \\mid D=1] = E[Y^1 \\mid D=0] = E[Y^1]$$\n",
    "\n",
    "Therefore:\n",
    "\n",
    "$$E[Y \\mid D=1] - E[Y \\mid D=0] = E[Y^1] - E[Y^0] = \\text{ATE}$$\n",
    "\n",
    "The naive estimator becomes **unbiased** under randomization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 7. SUTVA: Stable Unit Treatment Value Assumption\n",
    "\n",
    "The potential outcome framework relies on a critical assumption called SUTVA, which has two components:\n",
    "\n",
    "### 1. No Interference\n",
    "\n",
    "One unit's treatment assignment does not affect another unit's potential outcomes:\n",
    "\n",
    "$$Y_i^d = Y_i^d(D_1, D_2, \\ldots, D_n) \\text{ depends only on } D_i$$\n",
    "\n",
    "**Violations:**\n",
    "- Vaccine trials: Your vaccination protects others (**herd immunity**)\n",
    "- Classroom interventions: Tutoring one student may help their study partners\n",
    "- Market interventions: Promoting one product may cannibalize another\n",
    "\n",
    "### 2. No Hidden Variations in Treatment\n",
    "\n",
    "Treatment is well-defined — there is only one version of \"treatment\" and one version of \"control\":\n",
    "\n",
    "$$Y_i^1 \\text{ is the same regardless of how treatment is administered}$$\n",
    "\n",
    "**Violations:**\n",
    "- Drug dosage varies across treated patients\n",
    "- Job training programs have different instructors\n",
    "- \"Content optimization\" could mean different things for different products"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## Part II: Application\n",
    "\n",
    "In Part I we defined the potential outcome framework: individual treatment effects $\\delta_i = Y_i^1 - Y_i^0$, population parameters (ATE, ATT, ATC), and the decomposition showing how selection bias corrupts the naive estimator. We also saw that randomization eliminates selection bias by making treatment independent of potential outcomes.\n",
    "\n",
    "In this application, the simulator gives us a \"god's eye view\" — we observe both potential outcomes for every product. This lets us compute true treatment effects, verify the bias decomposition numerically, and demonstrate that randomization recovers the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import inspect\n",
    "\n",
    "# Third-party packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import Code\n",
    "from online_retail_simulator import simulate, load_job_results\n",
    "from online_retail_simulator.enrich import enrich\n",
    "from online_retail_simulator.enrich.enrichment_library import quantity_boost\n",
    "\n",
    "# Local imports\n",
    "from support import (\n",
    "    create_confounded_treatment,\n",
    "    generate_quality_score,\n",
    "    plot_balance_check,\n",
    "    plot_individual_effects_distribution,\n",
    "    plot_randomization_comparison,\n",
    "    plot_sample_size_convergence,\n",
    "    print_bias_decomposition,\n",
    "    print_ite_summary,\n",
    "    print_naive_estimator,\n",
    ")\n",
    "\n",
    "# Set seed for reproducibility of random samples shown in output displays\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Business Context\n",
    "\n",
    "**What would be the effect on sales if we improved product content quality?**\n",
    "\n",
    "An e-commerce company is considering investing in content optimization (better descriptions, images, etc.) for its product catalog. Before rolling this out to all products, they want to understand the causal effect of content optimization on revenue.\n",
    "\n",
    "In our simulation:\n",
    "\n",
    "| Variable | Notation | Description |\n",
    "|----------|----------|-------------|\n",
    "| Treatment | $D=1$ | Product receives content optimization |\n",
    "| Control | $D=0$ | Product keeps original content |\n",
    "| Outcome | $Y$ | Product revenue |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Data Generation\n",
    "\n",
    "We simulate 5,000 products with a single day of sales data. The simulation produces baseline metrics, from which we derive a quality score and assign treatment. The company selects the **lowest-quality** 30% of products for content optimization — a realistic business decision to invest where the need is greatest. This strategic selection creates confounding: treated products already had lower baseline revenue *before* any optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "!cat \"config_simulation.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Run simulation and load baseline metrics\n",
    "job_info = simulate(\"config_simulation.yaml\")\n",
    "metrics = load_job_results(job_info)[\"metrics\"]\n",
    "\n",
    "print(f\"Metrics records: {len(metrics)}\")\n",
    "print(f\"Unique products: {metrics['product_identifier'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "Code(inspect.getsource(create_confounded_treatment), language=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Apply the confounded treatment assignment\n",
    "TRUE_EFFECT = 0.5  # 50% revenue boost from content optimization\n",
    "\n",
    "confounded_products = create_confounded_treatment(\n",
    "    metrics,\n",
    "    treatment_fraction=0.3,\n",
    "    true_effect=TRUE_EFFECT,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"Products: {len(confounded_products)}\")\n",
    "print(f\"Treated: {confounded_products['D'].sum()} ({confounded_products['D'].mean():.1%})\")\n",
    "print(f\"Control: {(1 - confounded_products['D']).sum():.0f} ({1 - confounded_products['D'].mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 3. Naive Comparison\n",
    "\n",
    "A naive analyst — one who does not know (or ignores) the assignment mechanism — would simply compare mean outcomes across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Naive comparison: E[Y|D=1] - E[Y|D=0]\n",
    "treated = confounded_products[confounded_products[\"D\"] == 1]\n",
    "control = confounded_products[confounded_products[\"D\"] == 0]\n",
    "naive_estimate = treated[\"Y_observed\"].mean() - control[\"Y_observed\"].mean()\n",
    "\n",
    "# We have the potential outcomes, so compute the true ATE\n",
    "confounded_products[\"delta\"] = confounded_products[\"Y1\"] - confounded_products[\"Y0\"]\n",
    "ATE_true = confounded_products[\"delta\"].mean()\n",
    "\n",
    "print_naive_estimator(\n",
    "    treated[\"Y_observed\"].mean(),\n",
    "    control[\"Y_observed\"].mean(),\n",
    "    ATE_true,\n",
    "    title=\"Naive Estimator (Quality-Based Selection)\",\n",
    ")\n",
    "print(\"\\nThe naive estimator is BIASED under non-random selection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Why Does the Naive Estimate Fail?\n",
    "\n",
    "The naive estimate is biased because the assignment mechanism selected **struggling** products for treatment. Products with low quality scores have lower baseline revenue, so the treated group's mean outcome is pulled down *even before* any treatment effect kicks in.\n",
    "\n",
    "This is **negative selection bias**: the company targeted the weakest products, and their lower baseline revenue masks the positive treatment effect. In Part I's decomposition:\n",
    "\n",
    "$$E[Y \\mid D=1] - E[Y \\mid D=0] = \\text{ATE} + \\underbrace{E[Y^0 \\mid D=1] - E[Y^0 \\mid D=0]}_{\\text{Selection Bias } (< 0)}$$\n",
    "\n",
    "The selection bias term is negative because $E[Y^0 \\mid D=1] < E[Y^0 \\mid D=0]$ — treated products would have earned less *even without treatment*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 4. The Simulator's Advantage — Known Potential Outcomes\n",
    "\n",
    "Unlike real data, our simulator gives us **both potential outcomes** for every product. This \"god's eye view\" lets us:\n",
    "1. Compute true individual treatment effects\n",
    "2. Calculate true population parameters (ATE, ATT, ATC)\n",
    "3. Numerically verify the bias decomposition from Part I\n",
    "\n",
    "### The Fundamental Problem in Practice\n",
    "\n",
    "In real data, we observe only one potential outcome per product. The question marks below represent **counterfactuals** — outcomes that are fundamentally unobservable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# What we would OBSERVE in real data — only one potential outcome per product\n",
    "fundamental_df = confounded_products[confounded_products[\"Y_observed\"] > 0].sample(8, random_state=42).copy()\n",
    "fundamental_df[\"Y1_obs\"] = np.where(fundamental_df[\"D\"] == 1, fundamental_df[\"Y1\"], np.nan)\n",
    "fundamental_df[\"Y0_obs\"] = np.where(fundamental_df[\"D\"] == 0, fundamental_df[\"Y0\"], np.nan)\n",
    "\n",
    "fundamental_df[[\"product_identifier\", \"D\", \"Y_observed\", \"Y1_obs\", \"Y0_obs\"]].rename(\n",
    "    columns={\n",
    "        \"product_identifier\": \"Product\",\n",
    "        \"Y_observed\": \"Observed (Y)\",\n",
    "        \"Y1_obs\": \"Y(1)\",\n",
    "        \"Y0_obs\": \"Y(0)\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Full Information View\n",
    "\n",
    "The simulator knows both potential outcomes. We can see what each product *would have* earned under the alternative assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Full information: both potential outcomes are known\n",
    "full_info_sample = confounded_products[confounded_products[\"Y0\"] > 0].sample(8, random_state=42)\n",
    "full_info_sample[[\"product_identifier\", \"D\", \"Y_observed\", \"Y0\", \"Y1\"]].rename(\n",
    "    columns={\"product_identifier\": \"Product\", \"Y_observed\": \"Observed (Y)\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Individual Treatment Effects\n",
    "\n",
    "Because we have both potential outcomes, we can compute true individual treatment effects $\\delta_i = Y_i^1 - Y_i^0$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Individual treatment effects: delta_i = Y^1_i - Y^0_i\n",
    "print_ite_summary(confounded_products[\"delta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_individual_effects_distribution(\n",
    "    confounded_products[\"delta\"],\n",
    "    title=\"Distribution of Individual Treatment Effects ($)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### True Population Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# True ATE, ATT, ATC (we know both potential outcomes for all units)\n",
    "ATT_true = confounded_products[confounded_products[\"D\"] == 1][\"delta\"].mean()\n",
    "ATC_true = confounded_products[confounded_products[\"D\"] == 0][\"delta\"].mean()\n",
    "\n",
    "print(f\"True ATE: ${ATE_true:,.2f}\")\n",
    "print(f\"True ATT: ${ATT_true:,.2f}\")\n",
    "print(f\"True ATC: ${ATC_true:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "### Verifying the Bias Decomposition\n",
    "\n",
    "In Part I we derived that the naive estimator decomposes as:\n",
    "\n",
    "$$\\hat{\\delta}_{\\text{naive}} = \\text{ATE} + \\underbrace{E[Y^0 \\mid D=1] - E[Y^0 \\mid D=0]}_{\\text{Baseline Bias}} + \\underbrace{E[\\delta \\mid D=1] - E[\\delta]}_{\\text{Differential Treatment Effect Bias}}$$\n",
    "\n",
    "Because the simulator gives us $Y^0$ and $\\delta$ for every product, we can verify this decomposition numerically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Baseline bias: E[Y^0 | D=1] - E[Y^0 | D=0]\n",
    "baseline_treated = confounded_products[confounded_products[\"D\"] == 1][\"Y0\"].mean()\n",
    "baseline_control = confounded_products[confounded_products[\"D\"] == 0][\"Y0\"].mean()\n",
    "baseline_bias = baseline_treated - baseline_control\n",
    "\n",
    "# Differential treatment effect bias: E[delta | D=1] - E[delta]\n",
    "differential_effect_bias = ATT_true - ATE_true\n",
    "\n",
    "print_bias_decomposition(baseline_bias, differential_effect_bias, naive_estimate, ATE_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 5. Randomization Recovers the Truth\n",
    "\n",
    "In Part I we showed that under randomization, $(Y^1, Y^0) \\perp\\!\\!\\!\\perp D$, which eliminates selection bias and makes the naive estimator unbiased. We now demonstrate this by using the simulator's enrichment pipeline to assign treatment **randomly** to 30% of products.\n",
    "\n",
    "### Treatment Effect Configuration\n",
    "\n",
    "The enrichment pipeline applies a `quantity_boost` to randomly selected products:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "!cat \"config_enrichment_random.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Code(inspect.getsource(quantity_boost), language=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Apply random treatment using enrichment pipeline\n",
    "enrich(\"config_enrichment_random.yaml\", job_info)\n",
    "\n",
    "results = load_job_results(job_info)\n",
    "products = results[\"products\"]\n",
    "metrics_enriched = results[\"enriched\"]\n",
    "potential_outcomes = results[\"potential_outcomes\"]\n",
    "\n",
    "# Build full information DataFrame\n",
    "full_info_df = potential_outcomes.merge(\n",
    "    metrics_enriched[[\"product_identifier\", \"enriched\", \"revenue\"]],\n",
    "    on=\"product_identifier\",\n",
    ")\n",
    "full_info_df = full_info_df.rename(\n",
    "    columns={\"Y0_revenue\": \"Y0\", \"Y1_revenue\": \"Y1\", \"enriched\": \"Treated\", \"revenue\": \"Observed\"}\n",
    ")\n",
    "full_info_df[\"delta\"] = full_info_df[\"Y1\"] - full_info_df[\"Y0\"]\n",
    "\n",
    "print(f\"Baseline revenue: ${results['metrics']['revenue'].sum():,.0f}\")\n",
    "print(f\"Enriched revenue: ${metrics_enriched['revenue'].sum():,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Naive estimator under random assignment\n",
    "treated_random = full_info_df[full_info_df[\"Treated\"]]\n",
    "control_random = full_info_df[~full_info_df[\"Treated\"]]\n",
    "ATE_true_random = full_info_df[\"delta\"].mean()\n",
    "\n",
    "print_naive_estimator(\n",
    "    treated_random[\"Observed\"].mean(),\n",
    "    control_random[\"Observed\"].mean(),\n",
    "    ATE_true_random,\n",
    "    title=\"Naive Estimator (Random Assignment)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Covariate Balance Under Randomization\n",
    "\n",
    "Under random assignment, the distribution of covariates should be similar across treatment and control groups. Let's verify this by adding a quality score and checking balance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Add quality score and check balance under random assignment\n",
    "full_info_df[\"quality_score\"] = generate_quality_score(full_info_df[\"Y0\"])\n",
    "full_info_df[\"D_random\"] = full_info_df[\"Treated\"].astype(int)\n",
    "\n",
    "plot_balance_check(\n",
    "    full_info_df,\n",
    "    covariates=[\"quality_score\", \"Y0\"],\n",
    "    treatment_col=\"D_random\",\n",
    "    title=\"Covariate Balance: Random Assignment (BALANCED)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6. Diagnostics & Extensions\n",
    "\n",
    "### Monte Carlo: Random vs. Biased Assignment\n",
    "\n",
    "A single estimate may be close to the truth by luck. To demonstrate the systematic difference between random and biased selection, we run 500 simulations and compare the resulting sampling distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Monte Carlo simulation\n",
    "# 500 simulations provides stable estimates while keeping runtime reasonable (~5 seconds)\n",
    "n_simulations = 500\n",
    "n_treat = int(len(full_info_df) * 0.3)\n",
    "\n",
    "random_estimates = []\n",
    "biased_estimates = []\n",
    "\n",
    "for i in range(n_simulations):\n",
    "    # Random selection\n",
    "    random_idx = np.random.choice(len(full_info_df), n_treat, replace=False)\n",
    "    D_random = np.zeros(len(full_info_df))\n",
    "    D_random[random_idx] = 1\n",
    "    Y_random = np.where(D_random == 1, full_info_df[\"Y1\"], full_info_df[\"Y0\"])\n",
    "    est_random = Y_random[D_random == 1].mean() - Y_random[D_random == 0].mean()\n",
    "    random_estimates.append(est_random)\n",
    "\n",
    "    # Quality-based selection (always picks lowest quality)\n",
    "    bottom_idx = full_info_df.nsmallest(n_treat, \"quality_score\").index\n",
    "    D_biased = np.zeros(len(full_info_df))\n",
    "    D_biased[bottom_idx] = 1\n",
    "    Y_biased = np.where(D_biased == 1, full_info_df[\"Y1\"], full_info_df[\"Y0\"])\n",
    "    est_biased = Y_biased[D_biased == 1].mean() - Y_biased[D_biased == 0].mean()\n",
    "    biased_estimates.append(est_biased)\n",
    "\n",
    "print(f\"Random selection:  Mean = ${np.mean(random_estimates):,.0f}, Std = ${np.std(random_estimates):,.0f}\")\n",
    "print(f\"Quality selection: Mean = ${np.mean(biased_estimates):,.0f}, Std = ${np.std(biased_estimates):,.0f}\")\n",
    "print(f\"True ATE:          ${ATE_true_random:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_randomization_comparison(random_estimates, biased_estimates, ATE_true_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Uncertainty Decreases with Sample Size\n",
    "\n",
    "Under random assignment, the naive estimator is unbiased — it is centered on the true ATE. However, any single estimate will differ from the true value due to **sampling variability**.\n",
    "\n",
    "The standard error of the difference-in-means estimator decreases at rate $1/\\sqrt{n}$:\n",
    "\n",
    "$$\\text{SE}(\\hat{\\delta}) \\propto \\frac{1}{\\sqrt{n}}$$\n",
    "\n",
    "This means quadrupling the sample size cuts uncertainty in half."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Simulate at different sample sizes\n",
    "sample_sizes = [50, 100, 200, 500]\n",
    "n_simulations = 500\n",
    "estimates_by_size = {}\n",
    "\n",
    "for n in sample_sizes:\n",
    "    estimates = []\n",
    "    for _ in range(n_simulations):\n",
    "        # Random sample of n products\n",
    "        sample_idx = np.random.choice(len(full_info_df), n, replace=False)\n",
    "        sample = full_info_df.iloc[sample_idx]\n",
    "\n",
    "        # Random treatment assignment (50% treated)\n",
    "        n_treat_ss = n // 2\n",
    "        treat_idx = np.random.choice(n, n_treat_ss, replace=False)\n",
    "        D = np.zeros(n)\n",
    "        D[treat_idx] = 1\n",
    "\n",
    "        # Observed outcomes under random assignment\n",
    "        Y = np.where(D == 1, sample[\"Y1\"].values, sample[\"Y0\"].values)\n",
    "\n",
    "        # Naive estimate\n",
    "        est = Y[D == 1].mean() - Y[D == 0].mean()\n",
    "        estimates.append(est)\n",
    "\n",
    "    estimates_by_size[n] = estimates\n",
    "\n",
    "# Print summary\n",
    "print(\"Standard Deviation by Sample Size:\")\n",
    "for n in sample_sizes:\n",
    "    std = np.std(estimates_by_size[n])\n",
    "    print(f\"  n = {n:3d}: ${std:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot_sample_size_convergence(sample_sizes, estimates_by_size, ATE_true_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## SUTVA Considerations for E-commerce\n",
    "\n",
    "Our simulation assumes SUTVA holds. In real e-commerce settings, we should consider:\n",
    "\n",
    "| Violation | Example | Implication |\n",
    "|-----------|---------|-------------|\n",
    "| **Cannibalization** | Better content on Product A steals sales from Product B | Interference between products |\n",
    "| **Market saturation** | If ALL products are optimized, relative advantage disappears | Effect depends on treatment prevalence |\n",
    "| **Budget constraints** | Shoppers have fixed budgets; more on A means less on B | Zero-sum dynamics |\n",
    "| **Search ranking effects** | Optimized products rank higher, displacing others | Competitive interference |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "- **Athey, S. & Imbens, G. W. (2017)**. [The econometrics of randomized experiments](https://doi.org/10.1016/bs.hefe.2016.10.003). In *Handbook of Economic Field Experiments* (Vol. 1, pp. 73-140). Elsevier.\n",
    "\n",
    "- **Frölich, M. & Sperlich, S. (2019)**. *Impact Evaluation: Treatment Effects and Causal Analysis*. Cambridge University Press.\n",
    "\n",
    "- **Heckman, J. J., Urzua, S. & Vytlacil, E. (2006)**. Understanding instrumental variables in models with essential heterogeneity. *Review of Economics and Statistics*, 88(3), 389-432.\n",
    "\n",
    "- **Holland, P. W. (1986)**. Statistics and causal inference. *Journal of the American Statistical Association*, 81(396), 945-960.\n",
    "\n",
    "- **Imbens, G. W. (2020)**. [Potential outcome and directed acyclic graph approaches to causality: Relevance for empirical practice in economics](https://www.aeaweb.org/articles?id=10.1257/jel.20191597). *Journal of Economic Literature*, 58(4), 1129-1179.\n",
    "\n",
    "- **Imbens, G. W. & Rubin, D. B. (2015)**. *Causal Inference in Statistics, Social, and Biomedical Sciences*. Cambridge University Press.\n",
    "\n",
    "- **Rosenbaum, P. R. (2002)**. Overt bias in observational studies. In *Observational Studies* (pp. 71-104). Springer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
