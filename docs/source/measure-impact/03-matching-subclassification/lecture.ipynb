{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Matching and Subclassification\n",
    "\n",
    "> **Reference:** *Causal Inference: The Mixtape*, Chapter 5: Matching and Subclassification (pp. 175-230)\n",
    "\n",
    "This lecture introduces methods for causal inference when selection into treatment depends on observed covariates. We apply these concepts using the Online Retail Simulator to answer: **Can subclassification and matching recover the true treatment effect when confounding involves multiple continuous covariates?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part I: Theory\n",
    "\n",
    "This section covers the theoretical foundations of matching and subclassification as presented in Cunningham's *Causal Inference: The Mixtape*, Chapter 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Selection on Observables\n",
    "\n",
    "In the previous lecture on directed acyclic graphs, we learned that the **backdoor criterion** tells us which variables to condition on to identify causal effects. When a set of observed covariates $X$ satisfies the backdoor criterion, we have a situation called **selection on observables**. This means that treatment assignment, while not random, depends only on variables we can measure and control for.\n",
    "\n",
    "### The Conditional Independence Assumption\n",
    "\n",
    "The key identifying assumption for all methods in this lecture is the **conditional independence assumption (CIA)**, also known as **unconfoundedness** or **ignorability**:\n",
    "\n",
    "$$(Y^1, Y^0) \\perp\\!\\!\\!\\perp D \\mid X$$\n",
    "\n",
    "where $\\perp\\!\\!\\!\\perp$ denotes statistical independence. This assumption states that, conditional on the observed covariates $X$, the potential outcomes are independent of treatment assignment. In plain language: once we account for the variables in $X$, treatment is \"as good as random.\"\n",
    "\n",
    "What does this mean in practice? Consider two individuals with identical values of $X$. Under CIA, the fact that one received treatment and the other did not is essentially random—there are no other factors systematically driving both their treatment status and their outcomes.\n",
    "\n",
    "### Implications of CIA\n",
    "\n",
    "When CIA holds, the expected potential outcomes are equal across treatment groups for each value of $X$:\n",
    "\n",
    "$$E[Y^1 \\mid D=1, X] = E[Y^1 \\mid D=0, X] = E[Y^1 \\mid X]$$\n",
    "\n",
    "$$E[Y^0 \\mid D=1, X] = E[Y^0 \\mid D=0, X] = E[Y^0 \\mid X]$$\n",
    "\n",
    "This is powerful because it allows us to use observed outcomes from the control group to estimate the counterfactual for the treatment group (and vice versa) within each stratum defined by $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Common Support\n",
    "\n",
    "CIA alone is not sufficient for identification. We also need the **common support** (or **overlap**) assumption:\n",
    "\n",
    "$$0 < \\Pr(D=1 \\mid X) < 1$$\n",
    "\n",
    "This requires that for every value of $X$, there is a positive probability of being in both the treatment and control groups. Without common support, we cannot compare treated and untreated units with similar characteristics—some regions of the covariate space would have only treated units or only control units.\n",
    "\n",
    "| Assumption | Formal Statement | Intuition |\n",
    "|------------|------------------|------------|\n",
    "| **CIA** | $(Y^1, Y^0) \\perp\\!\\!\\!\\perp D \\mid X$ | Treatment is \"as good as random\" given $X$ |\n",
    "| **Common Support** | $0 < \\Pr(D=1 \\mid X) < 1$ | Both treated and control units exist for all $X$ |\n",
    "\n",
    "Together, these assumptions allow us to identify causal effects by comparing outcomes across treatment groups within strata defined by $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### From Assumptions to Identification\n",
    "\n",
    "Under CIA and common support, the **average treatment effect (ATE)** is identified as:\n",
    "\n",
    "$$\\delta_{ATE} = E[Y^1 - Y^0] = \\int \\left( E[Y \\mid X, D=1] - E[Y \\mid X, D=0] \\right) dF(X)$$\n",
    "\n",
    "The conditional expectations $E[Y \\mid X, D=1]$ and $E[Y \\mid X, D=0]$ are directly estimable from data. The integral averages these conditional effects over the distribution of $X$ in the population.\n",
    "\n",
    "The challenge is how to implement this in practice. With continuous covariates or many discrete covariates, we cannot simply compute separate means for each unique value of $X$. The methods we discuss below—subclassification and matching—provide practical approaches to this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2. Subclassification\n",
    "\n",
    "**Subclassification** is the most direct approach to satisfying the backdoor criterion. The idea is simple: divide the data into strata based on the confounding variable(s), compute treatment effects within each stratum, and then average across strata.\n",
    "\n",
    "### Motivating Example: Smoking and Mortality\n",
    "\n",
    "Consider a classic problem from epidemiology (simplified from Cochran 1968). We want to estimate the effect of smoking on mortality. The raw data shows that smokers have *lower* overall death rates than non-smokers—but should we believe this?\n",
    "\n",
    "The catch is that smokers in this sample are much younger on average. Age is a confounder: it influences both who smokes and mortality risk. Comparing the two groups directly mixes the effect of smoking with the effect of age composition. Subclassification removes this confounding by comparing within age groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### How Subclassification Works\n",
    "\n",
    "The subclassification procedure consists of three steps:\n",
    "\n",
    "1. **Stratify**: Divide the sample into $K$ mutually exclusive strata based on the covariate(s) $X$\n",
    "2. **Compare**: Within each stratum $k$, compute the difference in mean outcomes between treated and control units\n",
    "3. **Aggregate**: Take a weighted average of the within-stratum effects\n",
    "\n",
    "For the **average treatment effect on the treated (ATT)**, the estimator is:\n",
    "\n",
    "$$\\hat{\\delta}_{ATT} = \\sum_{k=1}^{K} \\left( \\bar{Y}^{1k} - \\bar{Y}^{0k} \\right) \\times \\frac{N_T^k}{N_T}$$\n",
    "\n",
    "where:\n",
    "- $\\bar{Y}^{1k}$ is the mean outcome for treated units in stratum $k$\n",
    "- $\\bar{Y}^{0k}$ is the mean outcome for control units in stratum $k$\n",
    "- $N_T^k$ is the number of treated units in stratum $k$\n",
    "- $N_T$ is the total number of treated units\n",
    "\n",
    "The weights $\\frac{N_T^k}{N_T}$ ensure that the strata contribute to the overall estimate in proportion to how many treated units they contain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Worked Example: Age-Adjusted Mortality Rates\n",
    "\n",
    "The data below (simplified from Cochran 1968) shows death rates per 1,000 person-years for smokers and non-smokers, broken down by age group. The **rate columns** give the death rate within each age stratum for each group. The **count columns** show how many people from each group fall into each age stratum—this is where the confounding lives.\n",
    "\n",
    "| Age Group | Rate (Smokers) | Rate (Non-Smokers) | # Smokers | # Non-Smokers |\n",
    "|-----------|---------------:|-------------------:|----------:|--------------:|\n",
    "| 20–40     | 20             | 10                 | 65        | 10            |\n",
    "| 41–70     | 40             | 30                 | 25        | 25            |\n",
    "| 71+       | 60             | 50                 | 10        | 65            |\n",
    "| **Total** |                |                    | **100**   | **100**       |\n",
    "\n",
    "Notice that smokers are much younger (65% under 40) while non-smokers are much older (65% over 70).\n",
    "\n",
    "**Naive comparison** — crude rates weighted by each group's own age distribution:\n",
    "\n",
    "$$\\text{Smokers (crude)} = 20 \\times \\tfrac{65}{100} + 40 \\times \\tfrac{25}{100} + 60 \\times \\tfrac{10}{100} = 29$$\n",
    "\n",
    "$$\\text{Non-smokers (crude)} = 10 \\times \\tfrac{10}{100} + 30 \\times \\tfrac{25}{100} + 50 \\times \\tfrac{65}{100} = 41$$\n",
    "\n",
    "The naive difference is $29 - 41 = -12$, suggesting smokers have *lower* mortality.\n",
    "\n",
    "**With subclassification** — within each age stratum, we compare directly:\n",
    "\n",
    "| Age Group | Smokers | Non-Smokers | Difference |\n",
    "|-----------|--------:|------------:|-----------:|\n",
    "| 20–40     | 20      | 10          | +10        |\n",
    "| 41–70     | 40      | 30          | +10        |\n",
    "| 71+       | 60      | 50          | +10        |\n",
    "\n",
    "Within every age group, smokers have a death rate 10 points *higher*. The naive comparison had the sign wrong because smokers were younger, and younger people die less regardless of smoking status. Subclassification removes this confounding by comparing like with like."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Covariate Balance\n",
    "\n",
    "The goal of subclassification is to achieve **covariate balance**—making the distribution of confounders similar across treatment and control groups. When the treated and control groups within each stratum have similar covariate values, we say the groups are **exchangeable** with respect to those covariates.\n",
    "\n",
    "Balance is the empirical manifestation of the conditional independence assumption. If CIA holds and we have balanced covariates, then any remaining difference in outcomes between treated and control units can be attributed to the treatment effect.\n",
    "\n",
    "We can check balance by comparing the means (or distributions) of covariates across treatment groups within each stratum. If the means are similar, we have achieved balance on that covariate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### The Curse of Dimensionality\n",
    "\n",
    "Subclassification works well when we have one or two discrete covariates. But what happens when we have many covariates, or when covariates are continuous?\n",
    "\n",
    "This is the **curse of dimensionality**. As the number of covariates $K$ grows, the number of strata grows exponentially. With just two binary covariates, we have $2^2 = 4$ strata. With ten binary covariates, we have $2^{10} = 1,024$ strata.\n",
    "\n",
    "The problem is that our sample size doesn't grow with the number of strata. As strata multiply:\n",
    "\n",
    "- Many strata become **empty** (no observations)\n",
    "- Many strata have observations of only one type (all treated or all control)\n",
    "- Even strata with both types may have very few observations, leading to imprecise estimates\n",
    "\n",
    "When a stratum contains only treated units or only control units, we have a **common support violation**—we cannot estimate the treatment effect in that stratum because we lack a comparison group.\n",
    "\n",
    "This limitation motivates the methods we discuss next: matching, which provides a more flexible approach to achieving covariate balance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 3. Exact Matching\n",
    "\n",
    "**Matching** takes a different approach to the identification problem. Instead of stratifying the data and computing within-stratum means, matching directly imputes the missing counterfactual for each treated unit by finding a similar control unit.\n",
    "\n",
    "### The Matching Idea\n",
    "\n",
    "Recall the **fundamental problem of causal inference**: for each treated unit $i$, we observe $Y_i^1$ but not $Y_i^0$. The treatment effect for unit $i$ is $\\delta_i = Y_i^1 - Y_i^0$, but we can only observe half of this difference.\n",
    "\n",
    "Matching addresses this by finding a control unit $j$ with covariate values identical (or very similar) to unit $i$. Under CIA, this control unit's outcome $Y_j$ serves as a valid estimate of unit $i$'s counterfactual outcome $Y_i^0$.\n",
    "\n",
    "For **exact matching**, we require that the matched control has exactly the same covariate values:\n",
    "\n",
    "$$X_{j(i)} = X_i$$\n",
    "\n",
    "where $j(i)$ denotes the control unit matched to treated unit $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### The Matching Estimator\n",
    "\n",
    "Once we have found matches, the ATT estimator is simply the average difference between each treated unit's outcome and its match's outcome:\n",
    "\n",
    "$$\\hat{\\delta}_{ATT} = \\frac{1}{N_T} \\sum_{D_i=1} \\left( Y_i - Y_{j(i)} \\right)$$\n",
    "\n",
    "This estimator has an intuitive interpretation: for each treated unit, we estimate its individual treatment effect by comparing its outcome to what a similar untreated unit achieved. We then average these individual effects.\n",
    "\n",
    "Note that this is an estimator of the ATT, not the ATE, because we are averaging over the treated units only. Each treated unit gets equal weight, and the implicit weighting reflects the distribution of $X$ among the treated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Example: Job Training and Earnings\n",
    "\n",
    "Consider a job training program where we want to estimate the effect on earnings. We have data on 5 trainees and 8 non-trainees, with age as the only covariate.\n",
    "\n",
    "**Trainees:**\n",
    "\n",
    "| Unit | Age | Earnings |\n",
    "|------|----:|---------:|\n",
    "| 1 | 18 | $9,500 |\n",
    "| 2 | 24 | $11,000 |\n",
    "| 3 | 27 | $11,750 |\n",
    "| 4 | 29 | $12,250 |\n",
    "| 5 | 33 | $13,250 |\n",
    "| **Mean** | **26.2** | **$11,550** |\n",
    "\n",
    "**Non-Trainees:**\n",
    "\n",
    "| Unit | Age | Earnings |\n",
    "|------|----:|---------:|\n",
    "| 1 | 40 | $13,500 |\n",
    "| 2 | 24 | $9,300 |\n",
    "| 3 | 44 | $14,500 |\n",
    "| 4 | 18 | $7,800 |\n",
    "| 5 | 29 | $10,500 |\n",
    "| 6 | 33 | $11,550 |\n",
    "| 7 | 27 | $10,100 |\n",
    "| 8 | 47 | $15,550 |\n",
    "| **Mean** | **32.8** | **$11,600** |\n",
    "\n",
    "The naive comparison suggests the program has no effect: trainees earn slightly *less* on average ($11,550 vs $11,600). But notice that trainees are younger on average (26.2 vs 32.8 years). Since earnings typically rise with age, this comparison is confounded—the non-trainee group includes older, higher-earning individuals who pull up the control mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Creating the Matched Sample\n",
    "\n",
    "For exact matching on age, we search the non-trainee table for a control unit with the same age as each trainee:\n",
    "\n",
    "| Trainee (Unit) | Age | Trainee Earnings | Match (Unit) | Match Earnings |\n",
    "|:--------------:|----:|-----------------:|:------------:|---------------:|\n",
    "| 1 | 18 | $9,500 | 4 | $7,800 |\n",
    "| 2 | 24 | $11,000 | 2 | $9,300 |\n",
    "| 3 | 27 | $11,750 | 7 | $10,100 |\n",
    "| 4 | 29 | $12,250 | 5 | $10,500 |\n",
    "| 5 | 33 | $13,250 | 6 | $11,550 |\n",
    "\n",
    "After matching, the matched control group has the same age distribution as the trainees. The groups are now **balanced** on age, and therefore **exchangeable** with respect to this covariate. Non-trainees 1, 3, and 8 (ages 40, 44, 47) are dropped because no trainee shares their age.\n",
    "\n",
    "The mean earnings of the matched controls is $9,850, compared to $11,550 for trainees. The matching estimate of the ATT is:\n",
    "\n",
    "$$\\hat{\\delta}_{ATT} = \\$11,550 - \\$9,850 = \\$1,700$$\n",
    "\n",
    "Once we compare trainees to non-trainees of the same age, the program increases earnings by $1,700—an effect that was completely hidden by the naive comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Limitations of Exact Matching\n",
    "\n",
    "Exact matching inherits the curse of dimensionality from subclassification. With multiple covariates, finding exact matches becomes increasingly difficult:\n",
    "\n",
    "- With continuous covariates (like age measured in days), exact matches may be impossible\n",
    "- With many discrete covariates, the probability of finding an exact match drops rapidly\n",
    "- Some treated units may have no exact match in the control group\n",
    "\n",
    "When exact matches cannot be found, we must either:\n",
    "1. Drop unmatched treated units (reducing sample size and potentially introducing selection bias)\n",
    "2. Use **approximate matching**, which we discuss next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 4. Approximate Matching\n",
    "\n",
    "In practice, exact matches are often unavailable. **Approximate matching** relaxes the requirement of identical covariate values, instead matching on units that are \"close\" in some sense.\n",
    "\n",
    "### The Need for Distance Metrics\n",
    "\n",
    "When we cannot find an exact match, we seek the \"nearest\" control unit. But what does \"nearest\" mean when comparing multiple covariates?\n",
    "\n",
    "With a single covariate, distance is straightforward: the distance between ages 25 and 27 is simply 2 years. But with multiple covariates—say, age and income—we need a way to combine distances across dimensions. Is someone who differs by 2 years in age and $1,000 in income \"closer\" or \"farther\" than someone who differs by 5 years in age and $200 in income?\n",
    "\n",
    "This is where **distance metrics** come in. A distance metric provides a principled way to measure the overall similarity between two units based on their covariate values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Distance Metrics\n",
    "\n",
    "The most common distance metrics are:\n",
    "\n",
    "**Euclidean Distance**\n",
    "\n",
    "The standard \"straight line\" distance in covariate space:\n",
    "\n",
    "$$||X_i - X_j|| = \\sqrt{(X_i - X_j)'(X_i - X_j)} = \\sqrt{\\sum_{n=1}^{K} (X_{ni} - X_{nj})^2}$$\n",
    "\n",
    "The problem with Euclidean distance is that it treats all covariates equally. If age is measured in years (range 18-65) and income in dollars (range $0-$500,000), income will dominate the distance calculation simply because of its larger scale.\n",
    "\n",
    "**Normalized Euclidean Distance**\n",
    "\n",
    "To address the scale problem, we can standardize each covariate by its variance:\n",
    "\n",
    "$$||X_i - X_j|| = \\sqrt{\\sum_{n=1}^{K} \\frac{(X_{ni} - X_{nj})^2}{\\hat{\\sigma}_n^2}}$$\n",
    "\n",
    "where $\\hat{\\sigma}_n^2$ is the sample variance of covariate $n$. Now a one-standard-deviation difference in any covariate contributes equally to the distance.\n",
    "\n",
    "**Mahalanobis Distance**\n",
    "\n",
    "The most sophisticated option accounts for correlations between covariates:\n",
    "\n",
    "$$||X_i - X_j|| = \\sqrt{(X_i - X_j)'\\hat{\\Sigma}_X^{-1}(X_i - X_j)}$$\n",
    "\n",
    "where $\\hat{\\Sigma}_X$ is the sample covariance matrix of the covariates. Mahalanobis distance not only standardizes by variance but also accounts for the correlation structure among covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### Comparison of Distance Metrics\n",
    "\n",
    "| Metric | Formula | Advantages | Disadvantages |\n",
    "|--------|---------|------------|---------------|\n",
    "| **Euclidean** | $\\sqrt{\\sum (X_{ni} - X_{nj})^2}$ | Simple, intuitive | Scale-dependent |\n",
    "| **Normalized Euclidean** | $\\sqrt{\\sum \\frac{(X_{ni} - X_{nj})^2}{\\sigma_n^2}}$ | Scale-invariant | Ignores correlations |\n",
    "| **Mahalanobis** | $\\sqrt{(X_i-X_j)'\\Sigma^{-1}(X_i-X_j)}$ | Scale-invariant, accounts for correlations | Requires invertible covariance matrix |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Nearest Neighbor Matching\n",
    "\n",
    "Once we have chosen a distance metric, **nearest neighbor matching** proceeds as follows:\n",
    "\n",
    "1. For each treated unit $i$, compute the distance to all control units\n",
    "2. Select the control unit $j(i)$ with the smallest distance to unit $i$\n",
    "3. Use $Y_{j(i)}$ as the imputed counterfactual for unit $i$\n",
    "\n",
    "The ATT estimator remains:\n",
    "\n",
    "$$\\hat{\\delta}_{ATT} = \\frac{1}{N_T} \\sum_{D_i=1} \\left( Y_i - Y_{j(i)} \\right)$$\n",
    "\n",
    "**Matching with multiple neighbors**: Sometimes we may want to use more than one control unit as a match. If we find $M$ nearest neighbors for each treated unit, we average their outcomes:\n",
    "\n",
    "$$\\hat{\\delta}_{ATT} = \\frac{1}{N_T} \\sum_{D_i=1} \\left( Y_i - \\frac{1}{M} \\sum_{m=1}^{M} Y_{j_m(i)} \\right)$$\n",
    "\n",
    "Using multiple matches reduces variance (more data points) but may increase bias (matches are farther away on average)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Matching Discrepancies and Bias\n",
    "\n",
    "With approximate matching, the matched control unit typically does not have exactly the same covariate values as the treated unit: $X_{j(i)} \\neq X_i$. This difference is called the **matching discrepancy**.\n",
    "\n",
    "Matching discrepancies introduce bias because the control unit's outcome reflects not just what the treated unit would have experienced under control, but also any systematic differences associated with having different covariate values.\n",
    "\n",
    "The key insight is that matching discrepancies tend to shrink as the sample size grows—with more potential controls, we can typically find closer matches. In the limit of an infinite control pool, exact matching becomes feasible and the bias disappears.\n",
    "\n",
    "In finite samples, researchers should:\n",
    "- Examine the quality of matches by comparing covariate distributions before and after matching\n",
    "- Use covariate balance diagnostics to assess whether matching has successfully balanced the groups\n",
    "- Consider whether remaining imbalances could materially affect the estimated treatment effect\n",
    "\n",
    "The practical takeaway is that approximate matching is a valuable tool, but researchers should be transparent about match quality and the potential for residual bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part II: Application\n",
    "\n",
    "In Part I we developed the theory of subclassification and matching: the conditional independence assumption identifies causal effects when treatment depends only on observed covariates, subclassification conditions by stratifying on those covariates, and matching imputes counterfactuals from similar control units.\n",
    "\n",
    "In this application, we know exactly how treatment was assigned. That knowledge — the **assignment mechanism** — is what makes causal inference possible. Understanding the assignment mechanism tells us what confounding looks like, why naive comparison fails, and which methods can fix it. We use production-grade implementations from the [**Impact Engine**](https://github.com/eisenhauerIO/impact-engine) to apply both methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": "# Standard library\nimport inspect\n\n# Third-party packages\nfrom impact_engine_measure import evaluate_impact, load_results\nfrom IPython.display import Code\nfrom online_retail_simulator import simulate, load_job_results\nimport pandas as pd\n\n# Local imports\nfrom support import (\n    compute_ground_truth_att,\n    create_confounded_treatment_multi,\n    plot_balance_love_plot,\n    plot_covariate_imbalance,\n    plot_method_comparison,\n    plot_strata_convergence,\n    plot_treatment_rates,\n    sweep_strata,\n)"
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 1. Business Context\n",
    "\n",
    "We return to the content optimization scenario from the previous lecture. An e-commerce company optimizes product listings to boost sales. In the DAGs lecture, confounding came from a single binary variable (product quality High/Low). Here we face a more realistic setting where the company's selection of which products to optimize depends on **three continuous product characteristics** — `quality_score`, `price`, and `impressions`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 2. Data Generation\n",
    "\n",
    "We simulate 5,000 products with a single day of sales data. The simulation produces baseline metrics — including `quality_score`, `price`, and `impressions` — that will serve as the covariates driving the assignment mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat config_simulation.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation and load results\n",
    "job_info = simulate(\"config_simulation.yaml\")\n",
    "metrics = load_job_results(job_info)[\"metrics\"]\n",
    "\n",
    "print(f\"Metrics records: {len(metrics)}\")\n",
    "print(f\"Unique products: {metrics['product_identifier'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 3. The Assignment Mechanism\n",
    "\n",
    "The optimization team did not randomly select products for content optimization. Instead, they prioritized **struggling products** — those with low quality scores, low prices, and few impressions. This is a sensible business strategy: invest resources where the need is greatest.\n",
    "\n",
    "But this strategic selection has a consequence for causal inference. The treatment and control groups differ systematically *before* any treatment is applied. Products selected for optimization already had lower baseline revenue — not because optimization hurts them, but because the company targeted products that were struggling on multiple dimensions.\n",
    "\n",
    "### Operationalizing Selection with a Logistic Model\n",
    "\n",
    "To formalize this selection process, we need a function that maps product characteristics to a treatment probability. The probability must lie in $[0, 1]$, which rules out a simple linear model. Instead, we use the **logistic (sigmoid) function**:\n",
    "\n",
    "$$P(D = 1 \\mid X) = \\frac{1}{1 + e^{-z}}, \\quad \\text{where} \\quad z = \\beta_1 X_1 + \\beta_2 X_2 + \\cdots + \\beta_K X_K$$\n",
    "\n",
    "The logistic function has three key properties: (1) its output is always in $[0, 1]$, (2) when $z = 0$ the probability is exactly $0.5$, and (3) the sign of each coefficient $\\beta_k$ determines the direction of its effect — negative coefficients mean that *lower* covariate values *increase* treatment probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Selection Coefficients\n",
    "\n",
    "In our setting, the covariates are standardized (zero mean, unit variance) so that each contributes on a common scale. The linear index is:\n",
    "\n",
    "$$z = -0.5 \\cdot \\text{quality\\_score}_z \\;-\\; 0.8 \\cdot \\text{price}_z \\;-\\; 0.3 \\cdot \\text{impressions}_z$$\n",
    "\n",
    "All three coefficients are **negative**, meaning lower covariate values increase treatment probability. The table below maps each coefficient to its business interpretation:\n",
    "\n",
    "| Covariate | Coefficient | Direction | Business Interpretation |\n",
    "|-----------|:----------:|-----------|------------------------|\n",
    "| `quality_score` | $-0.5$ | Lower quality $\\rightarrow$ higher $P(\\text{treat})$ | Struggling products prioritized |\n",
    "| `price` | $-0.8$ | Lower price $\\rightarrow$ higher $P(\\text{treat})$ | Budget products prioritized most strongly |\n",
    "| `impressions` | $-0.3$ | Fewer impressions $\\rightarrow$ higher $P(\\text{treat})$ | Low-visibility products slightly prioritized |\n",
    "\n",
    "### From Assignment Mechanism to Identifying Assumption\n",
    "\n",
    "Because this selection process uses **only** the three observable covariates `quality_score`, `price`, and `impressions`, the conditional independence assumption holds when we condition on them:\n",
    "\n",
    "$$(Y^1, Y^0) \\perp\\!\\!\\!\\perp D \\mid X, \\quad X = (\\text{quality\\_score},\\; \\text{price},\\; \\text{impressions})$$\n",
    "\n",
    "There are no unobserved factors driving selection. This is what justifies the conditioning-based methods — subclassification and matching — that we apply below. Both methods work by comparing treated and control products with similar values of $X$, which is exactly the set of variables that the assignment mechanism operates through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Code(inspect.getsource(create_confounded_treatment_multi), language=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": "# Apply the assignment mechanism to generate treatment and potential outcomes\nTRUE_EFFECT = 0.5  # 50% revenue boost from content optimization\n\nconfounded_products = create_confounded_treatment_multi(\n    metrics,\n    true_effect=TRUE_EFFECT,\n    coef_quality=-0.5,\n    coef_price=-0.8,\n    coef_impressions=-0.3,\n    seed=42,\n)\n\n# Save for the Impact Engine pipeline\nconfounded_products.to_csv(\"confounded_products.csv\", index=False)\n\nprint(f\"Products: {len(confounded_products)}\")\nprint(f\"Treated: {confounded_products['D'].sum()} ({confounded_products['D'].mean():.1%})\")\nprint(f\"Control: {(1 - confounded_products['D']).sum():.0f} ({1 - confounded_products['D'].mean():.1%})\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_treatment_rates(confounded_products, [\"quality_score\", \"price\", \"impressions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## 4. What Does the Naive Comparison Tell Us?\n",
    "\n",
    "A naive analyst — one who does not know (or ignores) the assignment mechanism — would simply compare mean outcomes across groups, treating the treatment/control split as if it were random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive comparison\n",
    "treated = confounded_products[confounded_products[\"D\"] == 1]\n",
    "control = confounded_products[confounded_products[\"D\"] == 0]\n",
    "naive_estimate = treated[\"Y_observed\"].mean() - control[\"Y_observed\"].mean()\n",
    "\n",
    "true_att = compute_ground_truth_att(confounded_products)\n",
    "\n",
    "print(\"Naive Comparison: E[Y|D=1] - E[Y|D=0]\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean revenue (treated):   ${treated['Y_observed'].mean():,.2f}\")\n",
    "print(f\"Mean revenue (control):   ${control['Y_observed'].mean():,.2f}\")\n",
    "print(f\"Naive estimate:           ${naive_estimate:,.2f}\")\n",
    "print(f\"\\nTrue ATT:                 ${true_att:,.2f}\")\n",
    "print(f\"Bias:                     ${naive_estimate - true_att:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### Why Does the Naive Estimate Fail?\n",
    "\n",
    "The naive estimate is biased because the **assignment mechanism** selected treated products based on their covariate values. The company chose products with lower quality scores, lower prices, and fewer impressions — and since all three covariates positively predict baseline revenue, the treated group has systematically lower revenue *even in the absence of any treatment effect*.\n",
    "\n",
    "This is **negative selection bias**: the treated group's lower baseline pulls down their mean outcome, masking (or reversing) the positive treatment effect. In the language of Part I, the CIA tells us that conditioning on $X$ would remove this bias. The histograms below show *why* conditioning is needed — the covariate distributions are shifted between groups, exactly as the assignment mechanism's negative coefficients predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_covariate_imbalance(confounded_products, [\"quality_score\", \"price\", \"impressions\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## 5. Subclassification with the Impact Engine\n",
    "\n",
    "The assignment mechanism operates through three continuous covariates. The CIA tells us: condition on these covariates and confounding disappears. Subclassification achieves this by discretizing each covariate into quantile-based bins, creating strata where products within the same bin have similar characteristics. Within each stratum, the assignment mechanism's influence is approximately removed — products are roughly comparable regardless of treatment status.\n",
    "\n",
    "With three continuous covariates, the curse of dimensionality from Part I applies directly: with `n_strata` set to 4, each covariate is split into 4 quantile-based bins, creating $4^3 = 64$ potential strata — many of which may lack common support. The `SubclassificationAdapter` from the **Impact Engine** handles this by dropping strata without both treated and control units."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": "### Configuration-to-Theory Mapping\n\nThe `MEASUREMENT.PARAMS` fields in the YAML configuration map directly to the components of our causal model. The `covariate_columns` are the three variables that drive the assignment mechanism — conditioning on them is what makes CIA hold.\n\n| YAML Config Field | Part I Concept |\n|-------------------|----------------|\n| `treatment_column` | Binary treatment indicator $D$ |\n| `covariate_columns` | Conditioning set $X$ from CIA: $(Y^1, Y^0) \\perp\\!\\!\\!\\perp D \\mid X$ |\n| `dependent_variable` | Observed outcome $Y$ |\n| `n_strata` | Number of strata $K$ in the subclassification estimator |\n| `estimand: \"att\"` | ATT weighting: $\\frac{N_T^k}{N_T}$ per stratum |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": "! cat config_subclassification.yaml"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": "# Run the subclassification pipeline\nsub_job = evaluate_impact(\"config_subclassification.yaml\", storage_url=\"./output/subclassification\")\nsub_result = load_results(sub_job)\n\nsub_estimate = sub_result.impact_results[\"data\"][\"impact_estimates\"][\"treatment_effect\"]\nn_strata = sub_result.impact_results[\"data\"][\"impact_estimates\"][\"n_strata\"]\nn_dropped = sub_result.impact_results[\"data\"][\"impact_estimates\"][\"n_strata_dropped\"]\n\nprint(\"Subclassification Results\")\nprint(\"=\" * 50)\nprint(f\"Estimated ATT:   ${sub_estimate:,.2f}\")\nprint(f\"True ATT:        ${true_att:,.2f}\")\nprint(f\"Bias:            ${sub_estimate - true_att:,.2f}\")\nprint(f\"\\nStrata used: {n_strata}  |  Strata dropped (no common support): {n_dropped}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": "# Examine stratum-level details\nsub_result.model_artifacts[\"stratum_details\"]"
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "### How Many Strata? Bias vs. the Curse of Dimensionality\n",
    "\n",
    "The choice of `n_strata` controls the bias-variance tradeoff discussed in Part I. With few strata per covariate, each bin is wide — treated and control products within the same stratum may still differ substantially, leaving residual confounding. Increasing the number of strata narrows the bins and reduces this within-stratum bias.\n",
    "\n",
    "But with three covariates, the total number of strata grows as $K^3$. As $K$ increases, many strata end up with only treated or only control products — a **common support violation**. These strata must be dropped, meaning the estimate is based on an increasingly selective subset of the data. The figure below sweeps across different values of $K$ to visualize both effects simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sweep across strata counts to show convergence and common support loss\n",
    "covariates = [\"quality_score\", \"price\", \"impressions\"]\n",
    "convergence_df = sweep_strata(confounded_products, [2, 3, 4, 5, 7, 10, 15, 20], covariates)\n",
    "plot_strata_convergence(convergence_df, true_att)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "The top panel shows the estimated ATT converging toward the true effect as $K$ increases — finer bins reduce within-stratum confounding, just as the theory predicts. But the bottom panel reveals the cost: the fraction of strata dropped for lack of common support rises sharply. With three covariates, the total strata grow as $K^3$, and the fixed sample of 5,000 products cannot populate them all. This is the curse of dimensionality in action — more strata improve bias but eventually exhaust the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "## 6. Nearest Neighbor Matching with the Impact Engine\n",
    "\n",
    "Subclassification discretizes the covariate space into bins, which can be lossy — two products in the same bin may still differ substantially on the covariates that drove treatment selection. Matching takes a different approach to the same problem.\n",
    "\n",
    "Instead of binning, matching directly implements the CIA logic: for each treated product, find a control product with the most similar covariate profile. If the match is close enough, the assignment mechanism's influence is effectively neutralized — we are comparing two products that would have had nearly the same treatment probability. The `NearestNeighbourMatchingAdapter` wraps [causalml](https://github.com/uber/causalml)'s `NearestNeighborMatch`, using a distance metric on the covariates to find closest matches. Because the three covariates have different scales and different coefficients in the assignment mechanism, the distance metric must account for scale differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": "### Configuration-to-Theory Mapping\n\nThe `covariate_columns` define the dimensions of the distance metric — these must include all variables that drive the assignment mechanism, so that conditional on a close match, treatment is effectively random.\n\n| YAML Config Field | Part I Concept |\n|-------------------|----------------|\n| `treatment_column` | Binary treatment indicator $D$ |\n| `covariate_columns` | Dimensions of the distance metric: $\\|X_i - X_j\\|$ |\n| `dependent_variable` | Observed outcome $Y$ |\n| `caliper` | Maximum matching discrepancy threshold (Section 4) |\n| `replace` | Matching with replacement — bias-variance tradeoff |\n| `ratio` | $M$ nearest neighbors: $\\frac{1}{M}\\sum_{m=1}^{M} Y_{j_m(i)}$ |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": "! cat config_matching.yaml"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": "# Run the nearest-neighbour matching pipeline\nnn_job = evaluate_impact(\"config_matching.yaml\", storage_url=\"./output/matching\")\nnn_result = load_results(nn_job)\n\nnn_att = nn_result.impact_results[\"data\"][\"impact_estimates\"][\"att\"]\nnn_atc = nn_result.impact_results[\"data\"][\"impact_estimates\"][\"atc\"]\nnn_ate = nn_result.impact_results[\"data\"][\"impact_estimates\"][\"ate\"]\nnn_att_se = nn_result.impact_results[\"data\"][\"impact_estimates\"][\"att_se\"]\n\nprint(\"Nearest Neighbor Matching Results\")\nprint(\"=\" * 50)\nprint(f\"ATT:   ${nn_att:,.2f}  (SE: ${nn_att_se:,.2f})\")\nprint(f\"ATC:   ${nn_atc:,.2f}\")\nprint(f\"ATE:   ${nn_ate:,.2f}\")\nprint(f\"\\nTrue ATT: ${true_att:,.2f}\")\nprint(f\"Bias:     ${nn_att - true_att:,.2f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "47",
   "metadata": {},
   "source": [
    "### Covariate Balance Diagnostics\n",
    "\n",
    "If matching successfully removes the assignment mechanism's influence, the covariate distributions of matched treated and control groups should be indistinguishable. The **standardized mean difference (SMD)** measures residual imbalance: the difference in covariate means between groups, normalized by the pooled standard deviation. An SMD below 0.1 suggests that the assignment mechanism's effect on that covariate has been effectively neutralized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": "# Print balance tables\nbalance_before = nn_result.model_artifacts[\"balance_before\"]\nbalance_after = nn_result.model_artifacts[\"balance_after\"]\n\nprint(\"Balance BEFORE matching:\")\nprint(balance_before)\nprint(\"\\nBalance AFTER matching:\")\nprint(balance_after)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_balance_love_plot(balance_before, balance_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "## 7. Which Method Best Recovers the True Effect?\n",
    "\n",
    "Because we built the assignment mechanism ourselves, we know the true ATT. This lets us verify that conditioning on the covariates that drive treatment selection — via either subclassification or matching — recovers the true causal effect. The naive estimate's failure confirms that the assignment mechanism creates real confounding; the methods' success confirms that conditioning on the right variables removes it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_method_comparison(\n",
    "    {\"Naive\": naive_estimate, \"Subclassification\": sub_estimate, \"NN Matching\": nn_att},\n",
    "    true_att,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics table\n",
    "summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Method\": [\"Naive\", \"Subclassification\", \"NN Matching\"],\n",
    "        \"Estimate ($)\": [naive_estimate, sub_estimate, nn_att],\n",
    "        \"Error ($)\": [naive_estimate - true_att, sub_estimate - true_att, nn_att - true_att],\n",
    "        \"% Error\": [\n",
    "            (naive_estimate - true_att) / true_att * 100,\n",
    "            (sub_estimate - true_att) / true_att * 100,\n",
    "            (nn_att - true_att) / true_att * 100,\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "summary[\"Estimate ($)\"] = summary[\"Estimate ($)\"].map(lambda x: f\"${x:,.2f}\")\n",
    "summary[\"Error ($)\"] = summary[\"Error ($)\"].map(lambda x: f\"${x:,.2f}\")\n",
    "summary[\"% Error\"] = summary[\"% Error\"].map(lambda x: f\"{x:+.1f}%\")\n",
    "\n",
    "print(f\"True ATT: ${true_att:,.2f}\")\n",
    "print()\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "- **Abadie, A. & Imbens, G. (2006)**. [Large sample properties of matching estimators for average treatment effects](https://doi.org/10.1111/j.1468-0262.2006.00655.x). *Econometrica*, 74(1), 235-267.\n",
    "\n",
    "- **Abadie, A. & Imbens, G. (2011)**. [Bias-corrected matching estimators for average treatment effects](https://doi.org/10.1198/jbes.2009.07333). *Journal of Business & Economic Statistics*, 29(1), 1-11.\n",
    "\n",
    "- **Cochran, W. G. (1968)**. [The effectiveness of adjustment by subclassification in removing bias in observational studies](https://doi.org/10.2307/2528036). *Biometrics*, 24(2), 295-313.\n",
    "\n",
    "- **Imbens, G. W. (2004)**. [Nonparametric estimation of average treatment effects under exogeneity: A review](https://doi.org/10.1162/003465304323023651). *Review of Economics and Statistics*, 86(1), 4-29.\n",
    "\n",
    "- **Rosenbaum, P. R. (2002)**. [*Observational Studies*](https://doi.org/10.1007/978-1-4757-3692-2) (2nd ed.). Springer.\n",
    "\n",
    "- **Rosenbaum, P. R. & Rubin, D. B. (1983)**. [The central role of the propensity score in observational studies for causal effects](https://doi.org/10.1093/biomet/70.1.41). *Biometrika*, 70(1), 41-55.\n",
    "\n",
    "- **Stuart, E. A. (2010)**. [Matching methods for causal inference: A review and a look forward](https://doi.org/10.1214/09-STS313). *Statistical Science*, 25(1), 1-21."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}