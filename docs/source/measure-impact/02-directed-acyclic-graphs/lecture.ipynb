{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Directed Acyclic Graphs\n",
    "\n",
    "> **Reference:** *Causal Inference: The Mixtape*, Chapter 3: Directed Acyclic Graphs (pp. 67-117)\n",
    "\n",
    "This lecture introduces directed acyclic graphs (DAGs) as a tool for reasoning about causal relationships. We apply these concepts using the Online Retail Simulator to answer: **Why does our naive analysis suggest content optimization hurts sales?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part I: Theory\n",
    "\n",
    "This section covers the theoretical foundations of directed acyclic graphs as presented in Cunningham's *Causal Inference: The Mixtape*, Chapter 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library\n",
    "import inspect\n",
    "\n",
    "# Third-party packages\n",
    "from IPython.display import Code\n",
    "\n",
    "# Local imports\n",
    "from support import draw_police_force_example, simulate_police_force_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 1. Introduction to DAG Notation\n",
    "\n",
    "A **directed acyclic graph (DAG)** is a visual representation of causal relationships between variables.\n",
    "\n",
    "### Core Components\n",
    "\n",
    "| Element | Representation | Meaning |\n",
    "|---------|----------------|----------|\n",
    "| **Node** | Circle | A random variable |\n",
    "| **Arrow** | Directed edge (→) | Direct causal effect |\n",
    "| **Path** | Sequence of edges | Connection between variables |\n",
    "\n",
    "### Key Properties\n",
    "\n",
    "1. **Directed**: Arrows point in one direction (cause → effect)\n",
    "2. **Acyclic**: No variable can cause itself (no loops)\n",
    "3. **Causality flows forward**: Time moves in the direction of arrows\n",
    "\n",
    "### What DAGs Encode\n",
    "\n",
    "DAGs encode **qualitative causal knowledge**:\n",
    "- What IS happening: drawn arrows\n",
    "- What is NOT happening: missing arrows (equally important!)\n",
    "\n",
    "A missing arrow from A to B claims that A does not directly cause B."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Simple DAG: Treatment → Outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "![Simple Causal Relationship](dag_simple.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 2. Paths: Direct and Backdoor\n",
    "\n",
    "A **path** is any sequence of edges connecting two nodes, regardless of arrow direction.\n",
    "\n",
    "### Types of Paths\n",
    "\n",
    "| Path Type | Direction | Interpretation |\n",
    "|-----------|-----------|----------------|\n",
    "| **Direct/Causal** | D → ... → Y | The causal effect we want |\n",
    "| **Backdoor** | D ← ... → Y | Spurious correlation (bias!) |\n",
    "\n",
    "### The Backdoor Problem\n",
    "\n",
    "Backdoor paths create **spurious correlations** between D and Y:\n",
    "- They make D and Y appear related even without a causal effect\n",
    "- This is the graphical representation of **selection bias**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "![Confounded Relationship](dag_confounder.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Path Analysis\n",
    "\n",
    "| Path | Type |\n",
    "|------|------|\n",
    "| D → Y | Direct causal path (what we want to estimate) |\n",
    "| D ← X → Y | Backdoor path (creates bias) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 3. Confounders\n",
    "\n",
    "A **confounder** is a variable that:\n",
    "1. Causes the treatment (D)\n",
    "2. Causes the outcome (Y)\n",
    "3. Is NOT on the causal path from D to Y\n",
    "\n",
    "### Observed vs. Unobserved\n",
    "\n",
    "| Type | In DAG | Implication |\n",
    "|------|--------|-------------|\n",
    "| **Observed** | Solid circle | Can condition on it |\n",
    "| **Unobserved** | Dashed circle | Cannot directly control |\n",
    "\n",
    "### Classic Example: Education and Earnings\n",
    "\n",
    "Consider estimating the return to education:\n",
    "- **Treatment**: Years of education\n",
    "- **Outcome**: Earnings\n",
    "- **Confounders**: Ability, family background, motivation\n",
    "\n",
    "People with higher ability tend to:\n",
    "- Get more education (ability → education)\n",
    "- Earn more regardless of education (ability → earnings)\n",
    "\n",
    "This creates a backdoor path that inflates naive estimates of education's effect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "![Education and Earnings DAG](dag_education.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 4. Colliders and Collider Bias\n",
    "\n",
    "A **collider** is a variable where two arrows point INTO it:\n",
    "\n",
    "![Collider Structure](dag_collider.svg)\n",
    "\n",
    "### Key Insight About Colliders\n",
    "\n",
    "Colliders have a **special property**: they naturally BLOCK paths!\n",
    "\n",
    "| Situation | Path Status |\n",
    "|-----------|-------------|\n",
    "| Leave collider alone | Path is CLOSED (blocked) |\n",
    "| Condition on collider | Path is OPENED (creates bias!) |\n",
    "\n",
    "### Why Conditioning Opens Colliders\n",
    "\n",
    "Conditioning on a collider makes its causes appear correlated, even if they're independent in the population.\n",
    "\n",
    "### Police Use of Force: Sample Selection as a Collider\n",
    "\n",
    "Consider studying whether police use more force against minorities:\n",
    "\n",
    "- **D (Treatment)**: Minority status\n",
    "- **Y (Outcome)**: Use of force\n",
    "- **M (Collider)**: Police stop (sample selection)\n",
    "- **U (Unobserved)**: Suspicion/perceived threat\n",
    "\n",
    "![Police Use of Force DAG](police_force_dag.svg)\n",
    "\n",
    "**The selection problem:**\n",
    "- Minorities are more likely to be stopped (D → M)\n",
    "- Suspicion affects both stops and force (U → M, U → Y)\n",
    "- Administrative data only includes stopped individuals\n",
    "\n",
    "**Why this attenuates discrimination estimates:**\n",
    "\n",
    "Among stopped individuals (M = 1), non-minorities (D = 0) who got stopped probably had high suspicion (U)—that's why they were stopped. Minorities (D = 1) who got stopped could have low or high suspicion, since they face higher stop rates regardless. So within the stopped sample, non-minorities are disproportionately high-suspicion, which correlates with more force (Y). This narrows the apparent gap between groups, masking the true discrimination effect (D → Y)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Simulation Setup\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Why Show the Simulation Code?</b>\n",
    "\n",
    "In causal inference, we face a fundamental challenge: we can never directly observe causal effects in real data. When we analyze observational data, we don't know the true causal structure—we can only make assumptions and hope our methods recover something meaningful. Simulation flips this around. By <i>constructing</i> data with a known causal structure, we create a laboratory where we can verify whether our intuitions and methods actually work. In the code below, we explicitly encoded that minorities face discrimination and that suspicion affects both stops and force. Because we built these relationships ourselves, we know the ground truth. This lets us <i>see</i>—not just theorize—how conditioning on a collider distorts our estimates. Throughout this course, simulation serves as our proving ground: if a method can't recover known effects in simulated data, we shouldn't trust it with real data where the stakes are higher and the truth is hidden.\n",
    "</div>\n",
    "\n",
    "The following function generates synthetic data with the collider structure described above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Code(inspect.getsource(simulate_police_force_data), language=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate population data\n",
    "police_data = simulate_police_force_data(n_population=5000, discrimination_effect=0.3, seed=42)\n",
    "police_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize collider bias\n",
    "draw_police_force_example(police_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Collider Bias in Action\n",
    "\n",
    "**True discrimination effect:** 30% increase in force for minorities\n",
    "\n",
    "| Sample | Correlation (Minority ↔ Force) |\n",
    "|--------|-------------------------------|\n",
    "| Full population | r = 0.22 |\n",
    "| Stopped individuals only | r = 0.12 |\n",
    "\n",
    "This is **collider bias**: conditioning on Stop (which depends on both Minority and Suspicion) attenuates the true relationship between minority status and force. The administrative data only includes stopped individuals, so naive analysis of police records underestimates discrimination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 5. The Backdoor Criterion\n",
    "\n",
    "The **backdoor criterion** provides a systematic way to identify what variables to condition on.\n",
    "\n",
    "### Definition\n",
    "\n",
    "A set of variables $Z$ satisfies the backdoor criterion relative to $(D, Y)$ if:\n",
    "\n",
    "1. No variable in $Z$ is a descendant of $D$\n",
    "2. $Z$ blocks every backdoor path from $D$ to $Y$\n",
    "\n",
    "### How to Block Paths\n",
    "\n",
    "| Node Type | To Block | To Open |\n",
    "|-----------|----------|----------|\n",
    "| **Non-collider** | Condition on it | Leave alone |\n",
    "| **Collider** | Leave alone | Condition on it |\n",
    "\n",
    "### Important Implications\n",
    "\n",
    "1. **Not all controls are good controls**: Conditioning on a collider creates bias\n",
    "2. **Minimal sufficiency**: You don't need to condition on everything—just enough to block backdoors\n",
    "3. **Multiple solutions**: Often several valid conditioning sets exist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 6. Choosing the Right Estimand\n",
    "\n",
    "The backdoor criterion tells us how to block spurious paths. But DAGs also help us reason about a subtler question: **which causal effect do we actually want to estimate?**\n",
    "\n",
    "Sometimes a variable is neither a confounder nor a collider—it's a **mediator** on the causal path. Whether to condition on it depends on the research question, not on removing bias.\n",
    "\n",
    "### Example: Discrimination in Hiring\n",
    "\n",
    "Consider studying gender discrimination in wages:\n",
    "- Gender → Occupation (women steered to lower-paying jobs)\n",
    "- Gender → Wages (direct discrimination)\n",
    "- Occupation → Wages\n",
    "\n",
    "**Question**: Should we control for occupation?\n",
    "\n",
    "**Answer**: It depends on what effect we want to measure!\n",
    "- **Total effect**: Don't control (captures both direct and indirect discrimination)\n",
    "- **Direct effect**: Control for occupation (discrimination within same job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "![Gender Discrimination DAG](dag_discrimination.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part II: Application\n",
    "\n",
    "We now apply DAG concepts to diagnose and solve a confounding problem using simulated data.\n",
    "\n",
    "### From Unconditional to Conditional Comparisons\n",
    "\n",
    "A **naive estimator** compares average outcomes between treated and untreated groups:\n",
    "\n",
    "$$\\hat{\\tau}_{\\text{naive}} = E[Y \\mid D=1] - E[Y \\mid D=0]$$\n",
    "\n",
    "This fails when confounders create systematic differences between groups. The treated and untreated have different distributions of background characteristics—we're comparing apples to oranges.\n",
    "\n",
    "The **backdoor criterion** tells us what to condition on. Once we block all backdoor paths, a conditional comparison becomes valid:\n",
    "\n",
    "$$\\hat{\\tau}_{\\text{conditional}} = E[Y \\mid D=1, X] - E[Y \\mid D=0, X]$$\n",
    "\n",
    "The key insight: the problem isn't the method (comparing means), it's *what* we compare. Conditioning on the right variables lets us compare like with like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Local imports\n",
    "from online_retail_simulator import simulate, load_job_results\n",
    "from support import (\n",
    "    apply_confounded_treatment,\n",
    "    compute_effects,\n",
    "    create_binary_quality,\n",
    "    plot_conditional_comparison,\n",
    "    plot_confounding_bar,\n",
    ")\n",
    "\n",
    "# Fix seed for reproducibility so that all results in this notebook are deterministic\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 1. Business Context: The Content Optimization Paradox\n",
    "\n",
    "An e-commerce company ran a content optimization program for some of its products. When they analyze the results, they find something puzzling:\n",
    "\n",
    "> **Products that received content optimization tend to have LOWER sales than those that didn't.**\n",
    "\n",
    "The content team is confused. Did their optimization work actually hurt sales?\n",
    "\n",
    "### The Underlying Reality\n",
    "\n",
    "What's actually happening:\n",
    "- **Struggling products** (low quality) were selected for content optimization\n",
    "- **Strong products** (high quality) sell well without optimization\n",
    "- Content optimization **does** increase sales (true causal effect is positive)\n",
    "\n",
    "But the **confounding** from product quality creates a **negative spurious correlation** that overwhelms the positive causal effect. We'll use DAGs to understand and solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 2. Drawing the DAG\n",
    "\n",
    "Let's represent this situation graphically:\n",
    "\n",
    "- **Quality** (`Q`): Product quality/strength (unobserved)\n",
    "- **Optimization** (`D`): Content optimization treatment\n",
    "- **Sales** (`Y`): Revenue\n",
    "\n",
    "Relationships:\n",
    "1. Quality → Sales (+): Better products sell more\n",
    "2. Quality → Optimization (−): Struggling products get optimized first\n",
    "3. Optimization → Sales (+): Optimization increases sales (TRUE causal effect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "![Content Optimization Paradox DAG](dag_optimization.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Path Analysis\n",
    "\n",
    "| Path | Type | Effect |\n",
    "|------|------|--------|\n",
    "| Optimization → Sales | Direct (causal) | True causal effect (+50% revenue boost) |\n",
    "| Optimization ← Quality → Sales | Backdoor | Creates negative bias (quality confounding) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 3. Generating Data with the Online Retail Simulator\n",
    "\n",
    "We use the **Online Retail Simulator** to generate realistic e-commerce data. The simulation configuration is defined in `\"config_simulation.yaml\"`. This gives us products with baseline sales metrics that we can then use to demonstrate confounding.\n",
    "\n",
    "### Data Generation Process\n",
    "\n",
    "1. **Simulate baseline data**: Generate products and their sales metrics\n",
    "2. **Create quality score**: Derive a quality measure from baseline revenue (the confounder)\n",
    "3. **Apply confounded treatment**: Assign content optimization based on quality (not randomly!)\n",
    "4. **Calculate outcomes**: Apply the true treatment effect to get observed sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate baseline data using the simulator\n",
    "! cat \"config_simulation.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation\n",
    "job_info = simulate(\"config_simulation.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load simulation results\n",
    "metrics = load_job_results(job_info)[\"metrics\"]\n",
    "\n",
    "print(f\"Metrics records: {len(metrics)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "### Creating the Confounded Treatment Assignment\n",
    "\n",
    "Now we create the confounding structure:\n",
    "1. **Quality**: Binary (High/Low) based on median baseline revenue\n",
    "2. **Treatment assignment**: Low quality products are more likely to be selected for optimization\n",
    "\n",
    "This mimics a realistic business scenario where struggling products get prioritized for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create binary quality from baseline revenue\n",
    "quality_df = create_binary_quality(metrics)\n",
    "\n",
    "# Step 3: Apply confounded treatment assignment\n",
    "# Low quality products more likely to be optimized\n",
    "TRUE_EFFECT = 0.5  # 50% revenue boost from optimization\n",
    "\n",
    "confounded_products = apply_confounded_treatment(\n",
    "    quality_df,\n",
    "    prob_treat_low=0.6,  # 60% of low quality products get optimized\n",
    "    prob_treat_high=0.2,  # 20% of high quality products get optimized\n",
    "    true_effect=TRUE_EFFECT,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(f\"Total products: {len(confounded_products)}\")\n",
    "print(f\"\\nQuality distribution:\")\n",
    "print(confounded_products[\"quality\"].value_counts())\n",
    "print(f\"\\nTreatment rates by quality:\")\n",
    "print(confounded_products.groupby(\"quality\")[\"D\"].mean().round(2))\n",
    "print(f\"\\n-> Low quality products are MORE likely to be treated (confounding!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the confounding structure\n",
    "plot_confounding_bar(confounded_products, title=\"Confounding in Content Optimization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## 4. What Does Naive Analysis Tell Us?\n",
    "\n",
    "Let's start with what a naive analyst might do: compare average sales between optimized and non-optimized products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive comparison: unconditional difference in means\n",
    "treated = confounded_products[confounded_products[\"D\"] == 1]\n",
    "control = confounded_products[confounded_products[\"D\"] == 0]\n",
    "\n",
    "naive_estimate = treated[\"Y_observed\"].mean() - control[\"Y_observed\"].mean()\n",
    "\n",
    "print(\"Naive Comparison: E[Y|D=1] - E[Y|D=0]\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Mean revenue (treated):   ${treated['Y_observed'].mean():,.2f}\")\n",
    "print(f\"Mean revenue (control):   ${control['Y_observed'].mean():,.2f}\")\n",
    "print(f\"Naive estimate:           ${naive_estimate:,.2f}\")\n",
    "print(f\"\\nTrue effect: +{TRUE_EFFECT:.0%} revenue boost\")\n",
    "print(f\"\\n-> The naive estimate suggests optimization HURTS sales!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "## 5. How Do We Apply the Backdoor Criterion?\n",
    "\n",
    "### Step 1: List all paths from Optimization to Sales\n",
    "\n",
    "1. **Optimization → Sales** (direct, causal)\n",
    "2. **Optimization ← Quality → Sales** (backdoor, non-causal)\n",
    "\n",
    "### Step 2: Identify which paths are open/closed\n",
    "\n",
    "- Path 1: Always open (it's causal)\n",
    "- Path 2: Open because Quality is a non-collider on this path\n",
    "\n",
    "### Step 3: Find conditioning set to block backdoors\n",
    "\n",
    "To block the backdoor path **Optimization ← Quality → Sales**:\n",
    "- Condition on **Quality**\n",
    "\n",
    "This satisfies the backdoor criterion:\n",
    "- Quality is not a descendant of Optimization\n",
    "- Conditioning on Quality blocks the backdoor path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## 6. How Do We Recover the Causal Effect?\n",
    "\n",
    "We condition on quality by computing treatment effects **within each quality bin**. This is the conditional comparison in action—we're comparing products with the same quality level, some optimized and some not.\n",
    "\n",
    "**Low Quality:**\n",
    "\n",
    "$$E[Y \\mid D=1, Q=\\text{Low}] - E[Y \\mid D=0, Q=\\text{Low}]$$\n",
    "\n",
    "**High Quality:**\n",
    "\n",
    "$$E[Y \\mid D=1, Q=\\text{High}] - E[Y \\mid D=0, Q=\\text{High}]$$\n",
    "\n",
    "The weighted average of these within-bin effects gives us an unbiased estimate of the treatment effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute within-bin treatment effects\n",
    "effects = compute_effects(confounded_products)\n",
    "\n",
    "print(\"Within-Bin Treatment Effects\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for quality in [\"Low\", \"High\"]:\n",
    "    bin_data = confounded_products[confounded_products[\"quality\"] == quality]\n",
    "    treated_mean = bin_data[bin_data[\"D\"] == 1][\"Y_observed\"].mean()\n",
    "    control_mean = bin_data[bin_data[\"D\"] == 0][\"Y_observed\"].mean()\n",
    "    n_treated = (bin_data[\"D\"] == 1).sum()\n",
    "    n_control = (bin_data[\"D\"] == 0).sum()\n",
    "\n",
    "    print(f\"\\n{quality} Quality (n={len(bin_data)}):\")\n",
    "    print(f\"  E[Y|D=1, Q={quality}] = ${treated_mean:,.2f}  (n={n_treated})\")\n",
    "    print(f\"  E[Y|D=0, Q={quality}] = ${control_mean:,.2f}  (n={n_control})\")\n",
    "    print(f\"  Effect: ${effects['by_quality'][quality]:,.2f}\")\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 50)\n",
    "print(f\"Weighted average (conditional estimate): ${effects['conditional']:,.2f}\")\n",
    "print(f\"Naive estimate:                          ${effects['naive']:,.2f}\")\n",
    "print(f\"True effect: +{TRUE_EFFECT:.0%} revenue boost\")\n",
    "print(f\"\\n-> Within-bin comparisons recover the POSITIVE effect!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual summary\n",
    "plot_conditional_comparison(confounded_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "effects = compute_effects(confounded_products)\n",
    "\n",
    "# Compute the true effect in dollar terms (average baseline revenue * effect percentage)\n",
    "true_effect_dollars = confounded_products[\"baseline_revenue\"].mean() * TRUE_EFFECT\n",
    "\n",
    "# Compute how close our conditional estimate is to the truth\n",
    "difference = abs(effects[\"conditional\"] - true_effect_dollars)\n",
    "pct_error = (difference / true_effect_dollars) * 100\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY: Content Optimization Effect Estimates\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"True causal effect:            +{TRUE_EFFECT:.0%} revenue boost\")\n",
    "print(f\"True effect (in $):            ${true_effect_dollars:,.2f}\")\n",
    "print(f\"\\nNaive (unconditional):         ${effects['naive']:,.2f}  <- WRONG SIGN!\")\n",
    "print(f\"Conditional (within-bin avg):  ${effects['conditional']:,.2f}  <- POSITIVE!\")\n",
    "print(f\"\\nDifference from truth:         ${difference:,.2f} ({pct_error:.1f}% error)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "## Additional resources\n",
    "\n",
    "- **Bellemare, M. & Bloem, J. (2020)**. The paper of how: Estimating treatment effects using the front-door criterion. *Working Paper*.\n",
    "\n",
    "- **Hünermund, P. & Bareinboim, E. (2019)**. Causal inference and data-fusion in econometrics. *arXiv preprint arXiv:1912.09104*.\n",
    "\n",
    "- **Imbens, G. W. (2020)**. Potential outcome and directed acyclic graph approaches to causality: Relevance for empirical practice in economics. *Journal of Economic Literature*, 58(4), 1129-1179.\n",
    "\n",
    "- **Manski, C. F. (1995)**. *Identification Problems in the Social Sciences*. Harvard University Press.\n",
    "\n",
    "- **Morgan, S. L. & Winship, C. (2014)**. *Counterfactuals and Causal Inference*. Cambridge University Press.\n",
    "\n",
    "- **Pearl, J. (2009a)**. *Causality: Models, Reasoning, and Inference* (2nd ed.). Cambridge University Press.\n",
    "\n",
    "- **Pearl, J. (2009b)**. Causal inference in statistics: An overview. *Statistics Surveys*, 3, 96-146.\n",
    "\n",
    "- **Pearl, J. (2012)**. The do-calculus revisited. *Proceedings of the 28th Conference on Uncertainty in Artificial Intelligence*.\n",
    "\n",
    "- **Peters, J., Janzing, D. & Schölkopf, B. (2017)**. *Elements of Causal Inference: Foundations and Learning Algorithms*. MIT Press."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
