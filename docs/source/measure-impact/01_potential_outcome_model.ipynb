{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Potential Outcome Model\n",
    "\n",
    "This lecture introduces the potential outcome framework for causal inference using a simulated online retail dataset. Our running example: **Does improving product content quality increase sales?**\n",
    "\n",
    "Unlike traditional datasets where true treatment effects are unknown, our simulator lets us SET the true effect and verify whether different estimation strategies recover it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "By the end of this lecture, you will be able to:\n",
    "\n",
    "- Define potential outcomes, treatment indicators, and observed outcomes\n",
    "- Understand individual vs population-level treatment effects (ATE, ATT, ATC)\n",
    "- Recognize why naive comparisons fail due to selection bias\n",
    "- Explain the SUTVA assumption and identify potential violations\n",
    "- Decompose selection bias into baseline and differential effect components\n",
    "- Demonstrate why randomization solves the selection problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -qq git+https://github.com/eisenhauerIO/tools-catalog-generator.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from online_retail_simulator import (\n",
    "    simulate,\n",
    "    load_job_results,\n",
    "    enrich,\n",
    "    register_enrichment_function,\n",
    ")\n",
    "\n",
    "from support import (\n",
    "    plot_individual_effects_distribution,\n",
    "    plot_treatment_parameters,\n",
    "    plot_bias_decomposition,\n",
    "    plot_randomization_comparison,\n",
    "    plot_time_series_treatment,\n",
    "    plot_bootstrap_distribution,\n",
    ")\n",
    "\n",
    "from enrichment_selection_bias import selection_bias_boost, get_treated_products\n",
    "\n",
    "# Register our custom enrichment function\n",
    "register_enrichment_function(\"selection_bias_boost\", selection_bias_boost)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Sample Data\n",
    "\n",
    "We simulate 500 products over a 60-day period (November 1 - December 31, 2024). The treatment (content optimization) begins on November 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(open(\"config_simulation.yaml\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run simulation\n",
    "job_info = simulate(\"config_simulation.yaml\")\n",
    "results = load_job_results(job_info)\n",
    "products = results[\"products\"]\n",
    "sales = results[\"sales\"]\n",
    "\n",
    "print(f\"Products: {len(products)}\")\n",
    "print(f\"Sales records: {len(sales)}\")\n",
    "print(f\"Date range: {sales['date'].min()} to {sales['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Potential Outcome Framework\n",
    "\n",
    "The potential outcome framework provides a precise language for defining causal effects. For each product $i$, we define:\n",
    "\n",
    "- $D_i \\in \\{0, 1\\}$: Treatment indicator (1 if product receives enhanced content, 0 otherwise)\n",
    "- $Y_i^1$: Potential outcome (revenue) if product $i$ receives enhanced content\n",
    "- $Y_i^0$: Potential outcome (revenue) if product $i$ does not receive enhanced content\n",
    "\n",
    "The **observed outcome** follows a switching equation:\n",
    "\n",
    "$$Y_i = D_i \\cdot Y_i^1 + (1 - D_i) \\cdot Y_i^0$$\n",
    "\n",
    "This means we only observe $Y_i^1$ for treated products and $Y_i^0$ for control products—never both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Fundamental Problem of Causal Inference\n",
    "\n",
    "Holland (1986) articulated the fundamental problem: **we cannot observe both potential outcomes for the same unit**. The counterfactual outcome is always missing.\n",
    "\n",
    "| Product | Treatment | Observed | $Y^1$ | $Y^0$ |\n",
    "|---------|-----------|----------|-------|-------|\n",
    "| A | Treated | \\$500 | \\$500 | ? |\n",
    "| B | Control | \\$300 | ? | \\$300 |\n",
    "| C | Treated | \\$450 | \\$450 | ? |\n",
    "\n",
    "The question marks represent the fundamental problem—we never observe what *would have happened* under the alternative treatment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Individual-Specific Treatment Effects\n",
    "\n",
    "The individual treatment effect for product $i$ is:\n",
    "\n",
    "$$\\delta_i = Y_i^1 - Y_i^0$$\n",
    "\n",
    "This measures how much product $i$'s revenue would change due to content optimization.\n",
    "\n",
    "**Simulator Advantage**: Unlike real data, we can actually compute true individual effects because we control the data generating process. Let's demonstrate by generating both potential outcomes for each product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment parameters\n",
    "EFFECT_SIZE = 0.5  # 50% boost\n",
    "TREATMENT_FRACTION = 0.3  # 30% of products\n",
    "TREATMENT_START = \"2024-11-15\"\n",
    "\n",
    "# Define pre and post treatment periods\n",
    "pre_treatment = sales[sales[\"date\"] < TREATMENT_START]\n",
    "post_treatment = sales[sales[\"date\"] >= TREATMENT_START]\n",
    "\n",
    "# Aggregate to product level for post-treatment period (baseline - no treatment applied yet)\n",
    "product_baseline = (\n",
    "    post_treatment.groupby(\"asin\")\n",
    "    .agg({\"revenue\": \"sum\", \"ordered_units\": \"sum\"})\n",
    "    .reset_index()\n",
    ")\n",
    "product_baseline.columns = [\"asin\", \"Y_0\", \"units_0\"]\n",
    "\n",
    "# Y_1 is Y_0 boosted by the effect size\n",
    "product_baseline[\"Y_1\"] = product_baseline[\"Y_0\"] * (1 + EFFECT_SIZE)\n",
    "\n",
    "# True individual treatment effect\n",
    "product_baseline[\"delta\"] = product_baseline[\"Y_1\"] - product_baseline[\"Y_0\"]\n",
    "product_baseline[\"delta_pct\"] = product_baseline[\"delta\"] / product_baseline[\"Y_0\"]\n",
    "\n",
    "print(f\"True effect size: {EFFECT_SIZE:.0%}\")\n",
    "print(f\"Mean individual effect: ${product_baseline['delta'].mean():,.2f}\")\n",
    "print(f\"Std of individual effects: ${product_baseline['delta'].std():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_individual_effects_distribution(\n",
    "    product_baseline[\"delta_pct\"],\n",
    "    true_effect=EFFECT_SIZE,\n",
    "    title=\"Distribution of Individual Treatment Effects\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that even with a fixed 50% effect size, individual effects vary because products have different baseline revenues. A product with \\$1000 baseline gains \\$500, while one with \\$100 baseline gains only \\$50."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population-Level Parameters\n",
    "\n",
    "Since we cannot observe individual effects in practice, we focus on population averages:\n",
    "\n",
    "| Parameter | Definition | Question Answered |\n",
    "|-----------|------------|-------------------|\n",
    "| **ATE** | $E[Y^1 - Y^0]$ | Average effect across ALL products |\n",
    "| **ATT** | $E[Y^1 - Y^0 \\mid D=1]$ | Effect among products that WERE optimized |\n",
    "| **ATC** | $E[Y^1 - Y^0 \\mid D=0]$ | Effect if we optimized the remaining products |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate true population parameters\n",
    "# For now, with uniform effect, ATE = ATT = ATC\n",
    "\n",
    "ATE_true = product_baseline[\"delta\"].mean()\n",
    "\n",
    "print(f\"True ATE: ${ATE_true:,.2f}\")\n",
    "print(\"\\nThis represents the average revenue increase from content optimization.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With heterogeneous effects by product size, we'd see ATE != ATT != ATC\n",
    "# Let's simulate this by making effect larger for higher-priced products\n",
    "\n",
    "# Merge price information\n",
    "product_with_price = product_baseline.merge(\n",
    "    products[[\"asin\", \"price\", \"category\"]], on=\"asin\"\n",
    ")\n",
    "\n",
    "# Create heterogeneous effect: higher-priced products benefit more\n",
    "median_price = product_with_price[\"price\"].median()\n",
    "product_with_price[\"effect_multiplier\"] = np.where(\n",
    "    product_with_price[\"price\"] > median_price, 1.2, 0.8\n",
    ")\n",
    "product_with_price[\"delta_hetero\"] = (\n",
    "    product_with_price[\"Y_0\"] * EFFECT_SIZE * product_with_price[\"effect_multiplier\"]\n",
    ")\n",
    "\n",
    "# Suppose we treat high-priced products\n",
    "product_with_price[\"D\"] = (product_with_price[\"price\"] > median_price).astype(int)\n",
    "\n",
    "ATE_hetero = product_with_price[\"delta_hetero\"].mean()\n",
    "ATT_hetero = product_with_price[product_with_price[\"D\"] == 1][\"delta_hetero\"].mean()\n",
    "ATC_hetero = product_with_price[product_with_price[\"D\"] == 0][\"delta_hetero\"].mean()\n",
    "\n",
    "print(\"With heterogeneous effects (high-priced products benefit more):\")\n",
    "print(f\"ATE: ${ATE_hetero:,.2f}\")\n",
    "print(f\"ATT: ${ATT_hetero:,.2f}\")\n",
    "print(f\"ATC: ${ATC_hetero:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_treatment_parameters(\n",
    "    ATE_hetero,\n",
    "    ATT_hetero,\n",
    "    ATC_hetero,\n",
    "    title=\"Population-Level Treatment Parameters (Heterogeneous Effects)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUTVA: Stable Unit Treatment Value Assumption\n",
    "\n",
    "The potential outcome framework relies on SUTVA, which requires:\n",
    "\n",
    "1. **No interference**: One product's treatment doesn't affect another product's outcomes\n",
    "2. **No hidden variations**: Treatment is well-defined (no multiple versions)\n",
    "\n",
    "### Potential SUTVA Violations in E-commerce\n",
    "\n",
    "| Violation | Example | Implication |\n",
    "|-----------|---------|-------------|\n",
    "| **Cannibalization** | Better content on Product A steals sales from Product B | Interference between products |\n",
    "| **Market saturation** | If ALL products are optimized, relative advantage disappears | Effect depends on treatment prevalence |\n",
    "| **Budget constraints** | Customers have fixed budgets; more on A means less on B | Zero-sum dynamics |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Estimation and Selection Bias\n",
    "\n",
    "The **naive estimator** compares average outcomes between treated and control groups:\n",
    "\n",
    "$$\\hat{\\delta}_{NAIVE} = E[Y \\mid D=1] - E[Y \\mid D=0]$$\n",
    "\n",
    "This equals the ATE only if treatment is independent of potential outcomes. In practice, businesses don't randomly select products for optimization—they prioritize their best sellers.\n",
    "\n",
    "Let's demonstrate this with our `selection_bias_boost` function that treats TOP performers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(open(\"config_enrichment_biased.yaml\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply biased selection enrichment\n",
    "biased_job = enrich(\"config_enrichment_biased.yaml\", job_info)\n",
    "biased_results = load_job_results(biased_job)\n",
    "biased_sales = biased_results[\"enriched\"]\n",
    "\n",
    "print(f\"Enriched sales records: {len(biased_sales)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify which products were treated (top performers)\n",
    "sales_list = sales.to_dict(\"records\")\n",
    "treated_products = get_treated_products(\n",
    "    sales_list, enrichment_fraction=TREATMENT_FRACTION, enrichment_start=TREATMENT_START\n",
    ")\n",
    "\n",
    "print(f\"Number of treated products: {len(treated_products)}\")\n",
    "print(f\"Treatment fraction: {len(treated_products) / len(products):.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate post-treatment outcomes\n",
    "post_biased = biased_sales[biased_sales[\"date\"] >= TREATMENT_START]\n",
    "product_outcomes = post_biased.groupby(\"asin\")[\"revenue\"].sum().reset_index()\n",
    "product_outcomes.columns = [\"asin\", \"Y\"]\n",
    "\n",
    "# Add treatment indicator\n",
    "product_outcomes[\"D\"] = product_outcomes[\"asin\"].isin(treated_products).astype(int)\n",
    "\n",
    "# Compute naive estimate\n",
    "treated_mean = product_outcomes[product_outcomes[\"D\"] == 1][\"Y\"].mean()\n",
    "control_mean = product_outcomes[product_outcomes[\"D\"] == 0][\"Y\"].mean()\n",
    "naive_estimate = treated_mean - control_mean\n",
    "\n",
    "print(f\"Mean revenue (Treated):  ${treated_mean:,.2f}\")\n",
    "print(f\"Mean revenue (Control):  ${control_mean:,.2f}\")\n",
    "print(f\"Naive estimate:          ${naive_estimate:,.2f}\")\n",
    "print(f\"True ATE:                ${ATE_true:,.2f}\")\n",
    "print(f\"\\nBias: ${naive_estimate - ATE_true:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Does the Naive Estimate Overestimate?\n",
    "\n",
    "The naive estimate includes both the true treatment effect AND selection bias:\n",
    "\n",
    "$$\\text{Naive} = \\text{ATE} + \\underbrace{E[Y^0 \\mid D=1] - E[Y^0 \\mid D=0]}_{\\text{Baseline Bias}}$$\n",
    "\n",
    "**Baseline bias** arises because treated products (top performers) would have had higher revenue *even without treatment*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate baseline bias\n",
    "# We need baseline (pre-treatment) revenue to see the selection\n",
    "pre_revenue = pre_treatment.groupby(\"asin\")[\"revenue\"].sum().reset_index()\n",
    "pre_revenue.columns = [\"asin\", \"baseline_revenue\"]\n",
    "\n",
    "product_outcomes = product_outcomes.merge(pre_revenue, on=\"asin\")\n",
    "\n",
    "# Baseline revenue by treatment status\n",
    "baseline_treated = product_outcomes[product_outcomes[\"D\"] == 1][\n",
    "    \"baseline_revenue\"\n",
    "].mean()\n",
    "baseline_control = product_outcomes[product_outcomes[\"D\"] == 0][\n",
    "    \"baseline_revenue\"\n",
    "].mean()\n",
    "baseline_bias = baseline_treated - baseline_control\n",
    "\n",
    "print(f\"Baseline revenue (Treated):  ${baseline_treated:,.2f}\")\n",
    "print(f\"Baseline revenue (Control):  ${baseline_control:,.2f}\")\n",
    "print(f\"Baseline bias:               ${baseline_bias:,.2f}\")\n",
    "print(\"\\nThis shows treated products were ALREADY better performers!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bias_decomposition(\n",
    "    ate=ATE_true,\n",
    "    baseline_bias=baseline_bias,\n",
    "    naive_estimate=naive_estimate,\n",
    "    title=\"Bias Decomposition: Selection on Performance\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomization as the Solution\n",
    "\n",
    "Randomization breaks the link between treatment assignment and potential outcomes:\n",
    "\n",
    "$$(Y^0, Y^1) \\perp\\!\\!\\!\\perp D$$\n",
    "\n",
    "Under randomization, the naive estimator is unbiased:\n",
    "\n",
    "$$E[Y \\mid D=1] - E[Y \\mid D=0] = E[Y^1] - E[Y^0] = \\text{ATE}$$\n",
    "\n",
    "Let's compare random selection (`combined_boost`) with biased selection (`selection_bias_boost`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random selection config:\")\n",
    "print(open(\"config_enrichment_random.yaml\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply random selection enrichment\n",
    "random_job = enrich(\"config_enrichment_random.yaml\", job_info)\n",
    "random_results = load_job_results(random_job)\n",
    "random_sales = random_results[\"enriched\"]\n",
    "\n",
    "# Get treated products (for random selection, we need to track this differently)\n",
    "# We'll identify by comparing pre/post revenue ratios\n",
    "post_random = random_sales[random_sales[\"date\"] >= TREATMENT_START]\n",
    "random_outcomes = post_random.groupby(\"asin\")[\"revenue\"].sum().reset_index()\n",
    "random_outcomes.columns = [\"asin\", \"Y\"]\n",
    "\n",
    "# Compare with original (no treatment) to identify treated\n",
    "post_original = sales[sales[\"date\"] >= TREATMENT_START]\n",
    "original_outcomes = post_original.groupby(\"asin\")[\"revenue\"].sum().reset_index()\n",
    "original_outcomes.columns = [\"asin\", \"Y_original\"]\n",
    "\n",
    "random_outcomes = random_outcomes.merge(original_outcomes, on=\"asin\")\n",
    "random_outcomes[\"ratio\"] = random_outcomes[\"Y\"] / random_outcomes[\"Y_original\"]\n",
    "random_outcomes[\"D\"] = (random_outcomes[\"ratio\"] > 1.1).astype(\n",
    "    int\n",
    ")  # Treated if >10% boost\n",
    "\n",
    "# Naive estimate under random assignment\n",
    "treated_mean_random = random_outcomes[random_outcomes[\"D\"] == 1][\"Y\"].mean()\n",
    "control_mean_random = random_outcomes[random_outcomes[\"D\"] == 0][\"Y\"].mean()\n",
    "naive_random = treated_mean_random - control_mean_random\n",
    "\n",
    "print(\"Random selection:\")\n",
    "print(f\"  Mean revenue (Treated):  ${treated_mean_random:,.2f}\")\n",
    "print(f\"  Mean revenue (Control):  ${control_mean_random:,.2f}\")\n",
    "print(f\"  Naive estimate:          ${naive_random:,.2f}\")\n",
    "print(f\"  True ATE:                ${ATE_true:,.2f}\")\n",
    "print(f\"  Bias:                    ${naive_random - ATE_true:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Comparison\n",
    "\n",
    "Let's run multiple simulations to see the distribution of estimates under random vs biased selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo simulation comparing random vs biased selection\n",
    "n_simulations = 100\n",
    "\n",
    "random_estimates = []\n",
    "biased_estimates = []\n",
    "\n",
    "# Get baseline data\n",
    "baseline_df = product_baseline.copy()\n",
    "\n",
    "for i in range(n_simulations):\n",
    "    # Random selection\n",
    "    n_treated = int(len(baseline_df) * TREATMENT_FRACTION)\n",
    "    random_idx = np.random.choice(len(baseline_df), n_treated, replace=False)\n",
    "    baseline_df[\"D_random\"] = 0\n",
    "    baseline_df.iloc[random_idx, baseline_df.columns.get_loc(\"D_random\")] = 1\n",
    "\n",
    "    # Observed outcome under random assignment\n",
    "    baseline_df[\"Y_random\"] = np.where(\n",
    "        baseline_df[\"D_random\"] == 1, baseline_df[\"Y_1\"], baseline_df[\"Y_0\"]\n",
    "    )\n",
    "\n",
    "    est_random = (\n",
    "        baseline_df[baseline_df[\"D_random\"] == 1][\"Y_random\"].mean()\n",
    "        - baseline_df[baseline_df[\"D_random\"] == 0][\"Y_random\"].mean()\n",
    "    )\n",
    "    random_estimates.append(est_random)\n",
    "\n",
    "    # Biased selection (top performers)\n",
    "    top_idx = baseline_df.nlargest(n_treated, \"Y_0\").index\n",
    "    baseline_df[\"D_biased\"] = 0\n",
    "    baseline_df.loc[top_idx, \"D_biased\"] = 1\n",
    "\n",
    "    # Observed outcome under biased assignment\n",
    "    baseline_df[\"Y_biased\"] = np.where(\n",
    "        baseline_df[\"D_biased\"] == 1, baseline_df[\"Y_1\"], baseline_df[\"Y_0\"]\n",
    "    )\n",
    "\n",
    "    est_biased = (\n",
    "        baseline_df[baseline_df[\"D_biased\"] == 1][\"Y_biased\"].mean()\n",
    "        - baseline_df[baseline_df[\"D_biased\"] == 0][\"Y_biased\"].mean()\n",
    "    )\n",
    "    biased_estimates.append(est_biased)\n",
    "\n",
    "print(\n",
    "    f\"Random selection:  Mean = ${np.mean(random_estimates):,.0f}, Std = ${np.std(random_estimates):,.0f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Biased selection:  Mean = ${np.mean(biased_estimates):,.0f}, Std = ${np.std(biased_estimates):,.0f}\"\n",
    ")\n",
    "print(f\"True ATE:          ${ATE_true:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_randomization_comparison(random_estimates, biased_estimates, ATE_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histograms show that:\n",
    "- **Random selection** (left): Estimates are centered around the true ATE\n",
    "- **Biased selection** (right): Estimates are systematically too high due to selection bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data and Imputation Perspective\n",
    "\n",
    "Causal inference can be framed as a missing data problem. For each product, one potential outcome is always missing:\n",
    "\n",
    "| Product | D | Y | $Y^1$ | $Y^0$ |\n",
    "|---------|---|---|-------|-------|\n",
    "| A | 1 | 500 | 500 | ? |\n",
    "| B | 0 | 300 | ? | 300 |\n",
    "\n",
    "We can impute the missing counterfactuals using various strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset showing the fundamental problem\n",
    "display_df = baseline_df[[\"asin\", \"Y_0\", \"Y_1\"]].copy()\n",
    "\n",
    "# Assign random treatment for demonstration\n",
    "np.random.seed(123)\n",
    "display_df[\"D\"] = np.random.binomial(1, TREATMENT_FRACTION, len(display_df))\n",
    "\n",
    "# Observed outcome\n",
    "display_df[\"Y\"] = np.where(display_df[\"D\"] == 1, display_df[\"Y_1\"], display_df[\"Y_0\"])\n",
    "\n",
    "# Mask the counterfactual\n",
    "display_df[\"Y_1_observed\"] = np.where(display_df[\"D\"] == 1, display_df[\"Y_1\"], np.nan)\n",
    "display_df[\"Y_0_observed\"] = np.where(display_df[\"D\"] == 0, display_df[\"Y_0\"], np.nan)\n",
    "\n",
    "# Show sample\n",
    "sample = display_df[[\"asin\", \"D\", \"Y\", \"Y_1_observed\", \"Y_0_observed\"]].sample(\n",
    "    10, random_state=42\n",
    ")\n",
    "sample.columns = [\"Product\", \"Treated\", \"Observed\", \"Y(1)\", \"Y(0)\"]\n",
    "sample[\"Treated\"] = sample[\"Treated\"].map({1: \"Yes\", 0: \"No\"})\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap for Uncertainty Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bootstrap estimation\n",
    "np.random.seed(456)\n",
    "n_bootstrap = 500\n",
    "bootstrap_estimates = []\n",
    "\n",
    "treated_outcomes = display_df[display_df[\"D\"] == 1][\"Y\"].values\n",
    "control_outcomes = display_df[display_df[\"D\"] == 0][\"Y\"].values\n",
    "\n",
    "for _ in range(n_bootstrap):\n",
    "    # Resample with replacement\n",
    "    treated_sample = np.random.choice(\n",
    "        treated_outcomes, len(treated_outcomes), replace=True\n",
    "    )\n",
    "    control_sample = np.random.choice(\n",
    "        control_outcomes, len(control_outcomes), replace=True\n",
    "    )\n",
    "\n",
    "    estimate = treated_sample.mean() - control_sample.mean()\n",
    "    bootstrap_estimates.append(estimate)\n",
    "\n",
    "ci_low, ci_high = plot_bootstrap_distribution(\n",
    "    bootstrap_estimates,\n",
    "    true_ate=ATE_true,\n",
    "    title=\"Bootstrap Distribution of Treatment Effect\",\n",
    ")\n",
    "\n",
    "print(f\"\\n95% Confidence Interval: [${ci_low:,.0f}, ${ci_high:,.0f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extensions: Time Series View\n",
    "\n",
    "The potential outcome framework extends to panel data. Before treatment ($t < t^*$), all products are in control state. After treatment ($t \\geq t^*$), treated products switch to the treatment potential outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare daily revenue: original vs enriched (random selection)\n",
    "daily_original = sales.groupby(\"date\")[\"revenue\"].sum().reset_index()\n",
    "daily_enriched = random_sales.groupby(\"date\")[\"revenue\"].sum().reset_index()\n",
    "\n",
    "# Merge for comparison\n",
    "daily_comparison = daily_original.merge(\n",
    "    daily_enriched, on=\"date\", suffixes=(\"_original\", \"_enriched\")\n",
    ")\n",
    "\n",
    "plot_time_series_treatment(\n",
    "    daily_comparison.rename(columns={\"revenue_enriched\": \"revenue\"}),\n",
    "    TREATMENT_START,\n",
    "    title=\"Daily Revenue with Treatment Effect\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The jump after November 15 reflects the treatment effect. This time-series view previews the **difference-in-differences** approach we'll cover in a later lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Concept | Definition | E-commerce Example |\n",
    "|---------|------------|-------------------|\n",
    "| Treatment ($D$) | Binary indicator | Content optimization (yes/no) |\n",
    "| Potential Outcomes | $Y^1$, $Y^0$ | Revenue with/without optimization |\n",
    "| Fundamental Problem | Cannot observe both $Y^1$ and $Y^0$ | Cannot see what sales would have been |\n",
    "| ATE | $E[Y^1 - Y^0]$ | Average effect across all products |\n",
    "| Selection Bias | $E[Y^0|D=1] - E[Y^0|D=0]$ | High-performers selected for optimization |\n",
    "| Randomization | $(Y^0, Y^1) \\perp\\!\\!\\!\\perp D$ | Random A/B test assignment |\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **The simulator advantage**: We can SET and KNOW the true treatment effect\n",
    "2. **Naive comparisons fail** when selection is non-random\n",
    "3. **Randomization solves** the selection bias problem\n",
    "4. This framework **underlies all causal identification strategies** we'll cover next"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
